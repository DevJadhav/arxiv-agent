ğŸ—ï¸ ArxivAgent CLI - System Architecture
Executive Summary
ArxivAgent is a production-grade, locally-running multi-agent CLI system for automated research paper discovery, analysis, and management. The system is designed for single-command installation and offline-first operation with intelligent cloud fallbacks.

1. High-Level System Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    USER INTERFACE LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Typer     â”‚  â”‚    Rich     â”‚  â”‚   Prompt    â”‚  â”‚   Theme     â”‚  â”‚  Config   â”‚  â”‚
â”‚  â”‚   CLI App   â”‚  â”‚   Console   â”‚  â”‚   Toolkit   â”‚  â”‚   Manager   â”‚  â”‚  Manager  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚                â”‚               â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ORCHESTRATION LAYER (LangGraph)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                           â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         State Machine / Workflow Engine                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚    â”‚
â”‚  â”‚  â”‚  START   â”‚â”€â”€â”€â–¶â”‚  ROUTE   â”‚â”€â”€â”€â–¶â”‚ EXECUTE  â”‚â”€â”€â”€â–¶â”‚   END    â”‚               â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                           â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                              AGENT POOL                                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚ Fetcher  â”‚  â”‚ Analyzer â”‚  â”‚ RAG Chat â”‚  â”‚Librarian â”‚  â”‚Trend Analyst â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  Agent   â”‚  â”‚  Agent   â”‚  â”‚  Agent   â”‚  â”‚  Agent   â”‚  â”‚    Agent     â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚             â”‚             â”‚             â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          â”‚      CORE SERVICES LAYER  â”‚             â”‚                â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          â–¼             â–¼             â–¼             â–¼                â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  API Client â”‚ â”‚ LLM Service â”‚ â”‚ RAG Engine  â”‚ â”‚  Storage    â”‚ â”‚  Scheduler  â”‚   â”‚
â”‚  â”‚   Manager   â”‚ â”‚   Manager   â”‚ â”‚   (Hybrid)  â”‚ â”‚   Service   â”‚ â”‚   Service   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚               â”‚               â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚        DATA & PERSISTENCE LAYER               â”‚               â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         â–¼               â–¼               â–¼               â–¼               â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   SQLite    â”‚ â”‚  ChromaDB/  â”‚ â”‚    File     â”‚ â”‚   Cache     â”‚ â”‚    Job      â”‚   â”‚
â”‚  â”‚  Metadata   â”‚ â”‚   Qdrant    â”‚ â”‚   System    â”‚ â”‚  (diskcache)â”‚ â”‚   Store     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚               â”‚               â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚          EXTERNAL SERVICES (Optional/Fallback)â”‚               â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         â–¼               â–¼               â–¼               â–¼               â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  arXiv API  â”‚ â”‚  Semantic   â”‚ â”‚  Claude API â”‚ â”‚ Ollama      â”‚ â”‚  CrossRef   â”‚   â”‚
â”‚  â”‚             â”‚ â”‚  Scholar    â”‚ â”‚  (Anthropic)â”‚ â”‚ (Local LLM) â”‚ â”‚    API      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Component Architecture Diagram
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚         arxiv-agent CLI             â”‚
                                    â”‚    $ arxiv-agent <command>          â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                 â”‚                                 â”‚
                    â–¼                                 â–¼                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Daily Digest    â”‚             â”‚   Paper Analysis  â”‚             â”‚   Interactive     â”‚
        â”‚     Commands      â”‚             â”‚     Commands      â”‚             â”‚   RAG Chat        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ digest config   â”‚             â”‚ â€¢ search <query>  â”‚             â”‚ â€¢ chat <paper_id> â”‚
        â”‚ â€¢ digest run      â”‚             â”‚ â€¢ analyze <id>    â”‚             â”‚ â€¢ chat history    â”‚
        â”‚ â€¢ digest schedule â”‚             â”‚ â€¢ paper2code <id> â”‚             â”‚ â€¢ chat clear      â”‚
        â”‚ â€¢ digest status   â”‚             â”‚ â€¢ compare <ids>   â”‚             â”‚ â€¢ chat export     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                                 â”‚                                 â”‚
                  â”‚                                 â”‚                                 â”‚
                  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
                  â”‚         â”‚                       â”‚                       â”‚         â”‚
                  â–¼         â–¼                       â–¼                       â–¼         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                              LangGraph Orchestrator                               â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚                            Shared State (TypedDict)                         â”‚  â”‚
        â”‚  â”‚  {                                                                          â”‚  â”‚
        â”‚  â”‚    "papers": List[Paper],      "analysis": Dict,                            â”‚  â”‚
        â”‚  â”‚    "chat_history": List[Msg],  "embeddings": np.array,                      â”‚  â”‚
        â”‚  â”‚    "user_prefs": UserPrefs,    "current_task": str,                         â”‚  â”‚
        â”‚  â”‚    "status": str,              "errors": List[Error]                        â”‚  â”‚
        â”‚  â”‚  }                                                                          â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚             â”‚               â”‚               â”‚             â”‚
                    â–¼             â–¼               â–¼               â–¼             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   FETCHER   â”‚â”‚  ANALYZER   â”‚â”‚  RAG CHAT   â”‚â”‚  LIBRARIAN  â”‚â”‚   TREND     â”‚
            â”‚    AGENT    â”‚â”‚    AGENT    â”‚â”‚    AGENT    â”‚â”‚    AGENT    â”‚â”‚   ANALYST   â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚â€¢ arXiv API  â”‚â”‚â€¢ PDF Parse  â”‚â”‚â€¢ Embeddings â”‚â”‚â€¢ Tagging    â”‚â”‚â€¢ Topic Modelâ”‚
            â”‚â€¢ Semantic   â”‚â”‚â€¢ Multi-pass â”‚â”‚â€¢ Hybrid     â”‚â”‚â€¢ Collectionsâ”‚â”‚â€¢ Citation   â”‚
            â”‚  Scholar    â”‚â”‚  LLM        â”‚â”‚  Search     â”‚â”‚â€¢ Dedup      â”‚â”‚  Analysis   â”‚
            â”‚â€¢ PDF DL     â”‚â”‚â€¢ Extraction â”‚â”‚â€¢ Context    â”‚â”‚â€¢ Export     â”‚â”‚â€¢ Recommend  â”‚
            â”‚â€¢ Metadata   â”‚â”‚â€¢ Summarize  â”‚â”‚  Memory     â”‚â”‚â€¢ Import     â”‚â”‚â€¢ Trends     â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚              â”‚              â”‚              â”‚              â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                            â”‚                            â”‚
                    â–¼                            â–¼                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   LLM Service   â”‚        â”‚   RAG Engine    â”‚        â”‚ Storage Service â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
            â”‚ â”‚Claude Opus  â”‚ â”‚        â”‚ â”‚Dense Search â”‚ â”‚        â”‚ â”‚  SQLite DB  â”‚ â”‚
            â”‚ â”‚(Paper2Code) â”‚ â”‚        â”‚ â”‚(SPECTER2)   â”‚ â”‚        â”‚ â”‚  (Metadata) â”‚ â”‚
            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
            â”‚ â”‚Claude Sonnetâ”‚ â”‚        â”‚ â”‚Sparse Searchâ”‚ â”‚        â”‚ â”‚ ChromaDB/   â”‚ â”‚
            â”‚ â”‚(Analysis)   â”‚ â”‚        â”‚ â”‚(BM25)       â”‚ â”‚        â”‚ â”‚ Qdrant      â”‚ â”‚
            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
            â”‚ â”‚Ollama Local â”‚ â”‚        â”‚ â”‚Cross-Encoderâ”‚ â”‚        â”‚ â”‚ File System â”‚ â”‚
            â”‚ â”‚(Fallback)   â”‚ â”‚        â”‚ â”‚Reranker     â”‚ â”‚        â”‚ â”‚ (PDFs)      â”‚ â”‚
            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. Data Flow Architecture
3.1 Daily Digest Flow
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DAILY DIGEST WORKFLOW                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CRON   â”‚     â”‚                    APScheduler                              â”‚
    â”‚ Trigger â”‚â”€â”€â”€â”€â–¶â”‚  Runs at configured time (e.g., 6:00 AM local)              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. FETCH PHASE                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚  â”‚ Load User   â”‚â”€â”€â”€â–¶â”‚ Query arXiv â”‚â”€â”€â”€â–¶â”‚  Enrich w/  â”‚â”€â”€â”€â–¶â”‚  Download   â”‚       â”‚
    â”‚  â”‚ Keywords    â”‚    â”‚ API (24hr)  â”‚    â”‚  Semantic   â”‚    â”‚    PDFs     â”‚       â”‚
    â”‚  â”‚ & Prefs     â”‚    â”‚             â”‚    â”‚  Scholar    â”‚    â”‚             â”‚       â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
    â”‚        â”‚                  â”‚                  â”‚                  â”‚               â”‚
    â”‚        â–¼                  â–¼                  â–¼                  â–¼               â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Papers: [{id, title, authors, abstract, citations, pdf_path}, ...]     â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. ANALYSIS PHASE (Overnight Processing)                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚  â”‚ Parse PDFs  â”‚â”€â”€â”€â–¶â”‚ Generate    â”‚â”€â”€â”€â–¶â”‚  Extract    â”‚â”€â”€â”€â–¶â”‚  Relevance  â”‚       â”‚
    â”‚  â”‚ (PyMuPDF4LLM)â”‚    â”‚ Summaries   â”‚    â”‚  Key Points â”‚    â”‚   Scoring   â”‚      â”‚
    â”‚  â”‚             â”‚    â”‚ (Claude)    â”‚    â”‚  & Methods  â”‚    â”‚             â”‚       â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
    â”‚                                                                â”‚                â”‚
    â”‚                                                                â–¼                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Analysis: {summary, methodology, findings, relevance_score, tags}      â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. OUTPUT PHASE                                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚  â”‚ Rank by     â”‚â”€â”€â”€â–¶â”‚ Generate    â”‚â”€â”€â”€â–¶â”‚   Save to   â”‚â”€â”€â”€â–¶â”‚   Notify    â”‚       â”‚
    â”‚  â”‚ Relevance   â”‚    â”‚ Markdown    â”‚    â”‚   Library   â”‚    â”‚    User     â”‚       â”‚
    â”‚  â”‚ & Citations â”‚    â”‚ Report      â”‚    â”‚             â”‚    â”‚             â”‚       â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OUTPUT: ~/.local/share/arxiv-agent/digests/2025-01-12.md                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  # Daily Research Digest - January 12, 2025                              â”‚   â”‚
    â”‚  â”‚                                                                          â”‚   â”‚
    â”‚  â”‚  ## ğŸ”¥ Top Papers (by relevance to your interests)                       â”‚   â”‚
    â”‚  â”‚  1. **Attention Is All You Need v2** - Score: 0.94                       â”‚   â”‚
    â”‚  â”‚     - Summary: ...                                                       â”‚   â”‚
    â”‚  â”‚     - Why relevant: Matches keywords [transformer, attention]            â”‚   â”‚
    â”‚  â”‚  ...                                                                     â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3.2 Interactive RAG Chat Flow
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              RAG CHAT WORKFLOW                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User: $ arxiv-agent chat arxiv:2401.12345
          > "What is the main contribution of this paper?"

                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. SESSION MANAGEMENT                                                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  Check for existing session (SQLite)                                    â”‚   â”‚
    â”‚  â”‚  â”œâ”€ If exists & < 24hr: Load context + history                          â”‚   â”‚
    â”‚  â”‚  â””â”€ If not: Create new session, load paper embeddings                   â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. HYBRID RETRIEVAL                                                            â”‚
    â”‚                                                                                 â”‚
    â”‚    Query: "main contribution"                                                   â”‚
    â”‚           â”‚                                                                     â”‚
    â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚           â”‚                   â”‚                      â”‚                          â”‚
    â”‚           â–¼                   â–¼                      â–¼                          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
    â”‚    â”‚   Dense     â”‚    â”‚   Sparse    â”‚    â”‚   Full-Text     â”‚                    â”‚
    â”‚    â”‚  (SPECTER2) â”‚    â”‚   (BM25)    â”‚    â”‚    Search       â”‚                    â”‚
    â”‚    â”‚  k=20       â”‚    â”‚   k=20      â”‚    â”‚    (SQLite)     â”‚                    â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â”‚           â”‚                  â”‚                    â”‚                             â”‚
    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
    â”‚                              â–¼                                                  â”‚
    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
    â”‚                    â”‚ Reciprocal Rank â”‚                                          â”‚
    â”‚                    â”‚     Fusion      â”‚                                          â”‚
    â”‚                    â”‚   (k=60 â†’ k=20) â”‚                                          â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
    â”‚                             â”‚                                                   â”‚
    â”‚                             â–¼                                                   â”‚
    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
    â”‚                    â”‚  Cross-Encoder  â”‚                                          â”‚
    â”‚                    â”‚    Reranker     â”‚                                          â”‚
    â”‚                    â”‚  (k=20 â†’ k=5)   â”‚                                          â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
    â”‚                             â”‚                                                   â”‚
    â”‚                             â–¼                                                   â”‚
    â”‚    Retrieved Chunks: [chunk_1, chunk_2, chunk_3, chunk_4, chunk_5]              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. CONTEXT ASSEMBLY                                                            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Context Window Assembly:                                               â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚  â”‚  â”‚  SYSTEM: You are analyzing paper "{title}"...                   â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  RETRIEVED_CONTEXT: [chunk_1...chunk_5]                         â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  CHAT_HISTORY: [last 10 messages, summarized if needed]         â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  USER_QUERY: "What is the main contribution..."                 â”‚    â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  4. LLM GENERATION                                                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Claude Sonnet 4.5 â†’ Streaming Response                                 â”‚    â”‚
    â”‚  â”‚  "The main contribution of this paper is a novel attention mechanism    â”‚    â”‚
    â”‚  â”‚   that achieves O(n) complexity instead of O(nÂ²)... [Section 3.2]"      â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  5. PERSISTENCE                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  â€¢ Save Q&A pair to chat_history table                                  â”‚    â”‚
    â”‚  â”‚  â€¢ Update session last_active timestamp                                 â”‚    â”‚
    â”‚  â”‚  â€¢ Index response for future retrieval                                  â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3.3 Paper-to-Code Flow (Claude Opus 4.5)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            PAPER-TO-CODE WORKFLOW                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User: $ arxiv-agent paper2code arxiv:2401.12345 --output ./my-implementation

                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PHASE 1: PLANNING (Claude Opus 4.5)                                           â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  Input: Full paper text + figures                                       â”‚   â”‚
    â”‚  â”‚  Output:                                                                â”‚   â”‚
    â”‚  â”‚  {                                                                      â”‚   â”‚
    â”‚  â”‚    "architecture": "Transformer with custom attention",                 â”‚   â”‚
    â”‚  â”‚    "components": ["MultiHeadAttention", "FeedForward", "LayerNorm"],    â”‚   â”‚
    â”‚  â”‚    "dependencies": ["torch", "einops", "flash-attn"],                   â”‚   â”‚
    â”‚  â”‚    "file_structure": {                                                  â”‚   â”‚
    â”‚  â”‚      "model/": ["attention.py", "layers.py", "transformer.py"],         â”‚   â”‚
    â”‚  â”‚      "train/": ["trainer.py", "config.py"],                             â”‚   â”‚
    â”‚  â”‚      "utils/": ["data.py", "metrics.py"]                                â”‚   â”‚
    â”‚  â”‚    },                                                                   â”‚   â”‚
    â”‚  â”‚    "implementation_order": ["attention.py", "layers.py", ...]           â”‚   â”‚
    â”‚  â”‚  }                                                                      â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PHASE 2: ANALYSIS (Per Component)                                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  For each component in implementation_order:                            â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Extract relevant sections from paper                         â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Identify equations and algorithms                            â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Map to existing library implementations (if any)             â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Generate detailed implementation spec                        â”‚    â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PHASE 3: CODE GENERATION (Iterative)                                           â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  For each file in dependency order:                                     â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚  â”‚  â”‚  Generate:                                                      â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Type-hinted Python code                                      â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Docstrings with paper section references                     â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Unit tests (pytest)                                          â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Usage examples                                               â”‚    â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
    â”‚  â”‚                                                                         â”‚    â”‚
    â”‚  â”‚  Validation:                                                            â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Syntax check (ast.parse)                                     â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Type check (mypy)                                            â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Import resolution                                            â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â€¢ Test execution                                               â”‚    â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PHASE 4: PROJECT SCAFFOLDING                                                   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Generated Structure:                                                   â”‚    â”‚
    â”‚  â”‚  my-implementation/                                                     â”‚    â”‚
    â”‚  â”‚  â”œâ”€â”€ pyproject.toml          # Dependencies, metadata                   â”‚    â”‚
    â”‚  â”‚  â”œâ”€â”€ README.md               # Setup, usage, paper reference            â”‚    â”‚
    â”‚  â”‚  â”œâ”€â”€ src/                                                               â”‚    â”‚
    â”‚  â”‚  â”‚   â”œâ”€â”€ model/                                                         â”‚    â”‚
    â”‚  â”‚  â”‚   â”‚   â”œâ”€â”€ attention.py    # Eq. 3.1-3.3                              â”‚    â”‚
    â”‚  â”‚  â”‚   â”‚   â”œâ”€â”€ layers.py       # Section 3.2                              â”‚    â”‚
    â”‚  â”‚  â”‚   â”‚   â””â”€â”€ transformer.py  # Full model                               â”‚    â”‚
    â”‚  â”‚  â”‚   â””â”€â”€ train/                                                         â”‚    â”‚
    â”‚  â”‚  â”‚       â””â”€â”€ trainer.py                                                 â”‚    â”‚
    â”‚  â”‚  â”œâ”€â”€ tests/                                                             â”‚    â”‚
    â”‚  â”‚  â”‚   â”œâ”€â”€ test_attention.py                                              â”‚    â”‚
    â”‚  â”‚  â”‚   â””â”€â”€ test_model.py                                                  â”‚    â”‚
    â”‚  â”‚  â””â”€â”€ examples/                                                          â”‚    â”‚
    â”‚  â”‚      â””â”€â”€ train_example.py                                               â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. Agent Architecture Details
4.1 Agent Interaction Pattern
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           MULTI-AGENT INTERACTION MODEL                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    ORCHESTRATOR     â”‚
                              â”‚    (LangGraph)      â”‚
                              â”‚                     â”‚
                              â”‚  â€¢ Route requests   â”‚
                              â”‚  â€¢ Manage state     â”‚
                              â”‚  â€¢ Handle errors    â”‚
                              â”‚  â€¢ Checkpoint       â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FETCHER   â”‚  â”‚  ANALYZER   â”‚  â”‚  RAG CHAT   â”‚  â”‚  LIBRARIAN  â”‚  â”‚   TREND     â”‚
â”‚    AGENT    â”‚  â”‚    AGENT    â”‚  â”‚    AGENT    â”‚  â”‚    AGENT    â”‚  â”‚   ANALYST   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Capabilities:â”‚  â”‚Capabilities:â”‚  â”‚Capabilities:â”‚  â”‚Capabilities:â”‚  â”‚Capabilities:â”‚
â”‚â€¢ API calls  â”‚  â”‚â€¢ PDF parse  â”‚  â”‚â€¢ Embedding  â”‚  â”‚â€¢ CRUD ops   â”‚  â”‚â€¢ Topic modelâ”‚
â”‚â€¢ Rate limit â”‚  â”‚â€¢ LLM calls  â”‚  â”‚â€¢ Retrieval  â”‚  â”‚â€¢ Tagging    â”‚  â”‚â€¢ Citation   â”‚
â”‚â€¢ Cache mgmt â”‚  â”‚â€¢ Extraction â”‚  â”‚â€¢ Generation â”‚  â”‚â€¢ Search     â”‚  â”‚â€¢ Trends     â”‚
â”‚â€¢ Retry      â”‚  â”‚â€¢ Summarize  â”‚  â”‚â€¢ Memory     â”‚  â”‚â€¢ Export     â”‚  â”‚â€¢ Recommend  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Tools:    â”‚  â”‚   Tools:    â”‚  â”‚   Tools:    â”‚  â”‚   Tools:    â”‚  â”‚   Tools:    â”‚
â”‚â€¢ arxiv_fetchâ”‚  â”‚â€¢ parse_pdf  â”‚  â”‚â€¢ embed_text â”‚  â”‚â€¢ add_paper  â”‚  â”‚â€¢ get_trends â”‚
â”‚â€¢ ss_lookup  â”‚  â”‚â€¢ analyze_llmâ”‚  â”‚â€¢ search_vec â”‚  â”‚â€¢ remove     â”‚  â”‚â€¢ topic_modelâ”‚
â”‚â€¢ download   â”‚  â”‚â€¢ extract    â”‚  â”‚â€¢ chat_llm   â”‚  â”‚â€¢ tag_paper  â”‚  â”‚â€¢ recommend  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚               â”‚               â”‚
         â”‚               â”‚               â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    SHARED STATE     â”‚
                              â”‚                     â”‚
                              â”‚  â€¢ papers[]         â”‚
                              â”‚  â€¢ analysis{}       â”‚
                              â”‚  â€¢ embeddings[]     â”‚
                              â”‚  â€¢ chat_history[]   â”‚
                              â”‚  â€¢ user_prefs{}     â”‚
                              â”‚  â€¢ tasks_queue[]    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4.2 State Machine Definition
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              LANGGRAPH STATE MACHINE                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  START  â”‚
                                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    PARSE_INPUT      â”‚
                              â”‚  Validate & Route   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    â”‚                    â”‚
                    â–¼                    â–¼                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   SEARCH    â”‚      â”‚   ANALYZE   â”‚      â”‚    CHAT     â”‚
            â”‚   PAPERS    â”‚      â”‚   PAPER     â”‚      â”‚   SESSION   â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                    â”‚                    â”‚
                   â–¼                    â–¼                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   FETCH     â”‚      â”‚    PARSE    â”‚      â”‚  RETRIEVE   â”‚
            â”‚  METADATA   â”‚      â”‚    PDF      â”‚      â”‚   CONTEXT   â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                    â”‚                    â”‚
                   â–¼                    â–¼                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   ENRICH    â”‚      â”‚   RUN_LLM   â”‚      â”‚  GENERATE   â”‚
            â”‚  (Semantic) â”‚      â”‚  ANALYSIS   â”‚      â”‚  RESPONSE   â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                    â”‚                    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚      PERSIST        â”‚
                              â”‚  Save to DB/Cache   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚      FORMAT         â”‚
                              â”‚   Output for CLI    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   END   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Error Handling:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Any Node   â”‚â”€â”€â”€â”€ Error â”€â”€â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚   HANDLE    â”‚
                                    â”‚   ERROR     â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚                 â”‚                 â”‚
                         â–¼                 â–¼                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   RETRY   â”‚    â”‚  FALLBACK â”‚    â”‚   FAIL    â”‚
                   â”‚  (w/ exp  â”‚    â”‚  (local   â”‚    â”‚  GRACEFUL â”‚
                   â”‚  backoff) â”‚    â”‚   model)  â”‚    â”‚           â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. Storage Architecture
5.1 Database Schema
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              SQLITE SCHEMA DESIGN                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    papers                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              TEXT PRIMARY KEY      -- arxiv:2401.12345                          â”‚
â”‚  title           TEXT NOT NULL                                                      â”‚
â”‚  authors         JSON NOT NULL         -- ["Author 1", "Author 2"]                  â”‚
â”‚  abstract        TEXT NOT NULL                                                      â”‚
â”‚  categories      JSON                  -- ["cs.AI", "cs.LG"]                        â”‚
â”‚  published_date  DATE                                                               â”‚
â”‚  pdf_path        TEXT                  -- Local path to downloaded PDF              â”‚
â”‚  pdf_hash        TEXT                  -- SHA256 for deduplication                  â”‚
â”‚  citation_count  INTEGER DEFAULT 0                                                  â”‚
â”‚  tldr            TEXT                  -- Semantic Scholar TLDR                     â”‚
â”‚  created_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â”‚  updated_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ 1:N
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                   analyses                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              INTEGER PRIMARY KEY AUTOINCREMENT                                  â”‚
â”‚  paper_id        TEXT REFERENCES papers(id)                                         â”‚
â”‚  analysis_type   TEXT NOT NULL         -- 'summary', 'methodology', 'full'          â”‚
â”‚  content         JSON NOT NULL         -- Structured analysis output                â”‚
â”‚  model_used      TEXT                  -- 'claude-sonnet-4-5-20250514'              â”‚
â”‚  token_count     INTEGER                                                            â”‚
â”‚  created_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                  collections                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              INTEGER PRIMARY KEY AUTOINCREMENT                                  â”‚
â”‚  name            TEXT NOT NULL UNIQUE                                               â”‚
â”‚  description     TEXT                                                               â”‚
â”‚  color           TEXT DEFAULT '#3B82F6'                                           â”‚
â”‚  created_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ N:M
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              paper_collections                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  paper_id        TEXT REFERENCES papers(id)                                         â”‚
â”‚  collection_id   INTEGER REFERENCES collections(id)                                 â”‚
â”‚  added_at        DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â”‚  PRIMARY KEY (paper_id, collection_id)                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 chat_sessions                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              TEXT PRIMARY KEY      -- UUID                                      â”‚
â”‚  paper_id        TEXT REFERENCES papers(id)                                         â”‚
â”‚  started_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â”‚  last_active     DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â”‚  message_count   INTEGER DEFAULT 0                                                  â”‚
â”‚  context_summary TEXT                  -- Compressed context for long sessions      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ 1:N
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                chat_messages                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              INTEGER PRIMARY KEY AUTOINCREMENT                                  â”‚
â”‚  session_id      TEXT REFERENCES chat_sessions(id)                                  â”‚
â”‚  role            TEXT NOT NULL         -- 'user', 'assistant'                       â”‚
â”‚  content         TEXT NOT NULL                                                      â”‚
â”‚  retrieved_chunks JSON                 -- Chunks used for this response             â”‚
â”‚  created_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    tags                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              INTEGER PRIMARY KEY AUTOINCREMENT                                  â”‚
â”‚  name            TEXT NOT NULL UNIQUE                                               â”‚
â”‚  auto_generated  BOOLEAN DEFAULT FALSE                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 paper_tags                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  paper_id        TEXT REFERENCES papers(id)                                         â”‚
â”‚  tag_id          INTEGER REFERENCES tags(id)                                        â”‚
â”‚  confidence      REAL                  -- For auto-generated tags                   â”‚
â”‚  PRIMARY KEY (paper_id, tag_id)                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               user_preferences                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  key             TEXT PRIMARY KEY                                                   â”‚
â”‚  value           JSON NOT NULL                                                      â”‚
â”‚  updated_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               reading_history                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id              INTEGER PRIMARY KEY AUTOINCREMENT                                  â”‚
â”‚  paper_id        TEXT REFERENCES papers(id)                                         â”‚
â”‚  action          TEXT NOT NULL         -- 'viewed', 'analyzed', 'chatted', 'saved'  â”‚
â”‚  duration_sec    INTEGER               -- Time spent (for learning)                 â”‚
â”‚  created_at      DATETIME DEFAULT CURRENT_TIMESTAMP                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Indexes:
  - CREATE INDEX idx_papers_published ON papers(published_date DESC);
  - CREATE INDEX idx_papers_categories ON papers(categories);
  - CREATE INDEX idx_chat_sessions_active ON chat_sessions(last_active DESC);
  - CREATE INDEX idx_reading_history_paper ON reading_history(paper_id, created_at);
  - CREATE VIRTUAL TABLE papers_fts USING fts5(title, abstract, content='papers');

5.2 Vector Store Schema (ChromaDB)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CHROMADB COLLECTIONS                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Collection: paper_chunks
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  id              string       -- "{paper_id}_{chunk_index}"                         â”‚
â”‚  embedding       float[768]   -- SPECTER2 embedding                                 â”‚
â”‚  document        string       -- Chunk text content                                 â”‚
â”‚  metadata:                                                                          â”‚
â”‚    paper_id      string       -- Reference to papers table                          â”‚
â”‚    chunk_index   int          -- Position in document                               â”‚
â”‚    section       string       -- "abstract", "introduction", "methods", etc.        â”‚
â”‚    page          int          -- PDF page number                                    â”‚
â”‚    char_start    int          -- Character offset in full text                      â”‚
â”‚    char_end      int                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Collection: paper_summaries
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  id              string       -- paper_id                                           â”‚
â”‚  embedding       float[768]   -- Embedding of full abstract + title                 â”‚
â”‚  document        string       -- Title + Abstract concatenated                      â”‚
â”‚  metadata:                                                                          â”‚
â”‚    title         string                                                             â”‚
â”‚    authors       string[]                                                           â”‚
â”‚    categories    string[]                                                           â”‚
â”‚    citation_count int                                                               â”‚
â”‚    published_date string                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Collection: user_queries
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  id              string       -- UUID                                               â”‚
â”‚  embedding       float[768]   -- Query embedding for learning                       â”‚
â”‚  document        string       -- Original query text                                â”‚
â”‚  metadata:                                                                          â”‚
â”‚    paper_id      string       -- Paper queried about                                â”‚
â”‚    session_id    string                                                             â”‚
â”‚    satisfaction  float        -- User feedback (optional)                           â”‚
â”‚    timestamp     string                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5.3 File System Structure
~/.local/share/arxiv-agent/           # XDG_DATA_HOME
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ arxiv-agent.db                # SQLite main database
â”‚   â”œâ”€â”€ jobs.db                       # APScheduler job store
â”‚   â””â”€â”€ checkpoints.db                # LangGraph checkpoints
â”œâ”€â”€ vectors/
â”‚   â””â”€â”€ chroma/                       # ChromaDB persistence
â”‚       â”œâ”€â”€ chroma.sqlite3
â”‚       â””â”€â”€ embeddings/
â”œâ”€â”€ pdfs/
â”‚   â”œâ”€â”€ 2024/
â”‚   â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”‚   â”œâ”€â”€ arxiv_2401.12345.pdf
â”‚   â”‚   â”‚   â””â”€â”€ arxiv_2401.12346.pdf
â”‚   â”‚   â””â”€â”€ 02/
â”‚   â””â”€â”€ 2025/
â”œâ”€â”€ digests/
â”‚   â”œâ”€â”€ 2025-01-12.md
â”‚   â”œâ”€â”€ 2025-01-11.md
â”‚   â””â”€â”€ archive/
â”œâ”€â”€ exports/
â”‚   â””â”€â”€ library_2025-01-12.json
â””â”€â”€ cache/
    â”œâ”€â”€ api_responses/
    â””â”€â”€ embeddings/

~/.config/arxiv-agent/                # XDG_CONFIG_HOME
â”œâ”€â”€ config.toml                       # User configuration
â”œâ”€â”€ themes/
â”‚   â”œâ”€â”€ default.toml
â”‚   â”œâ”€â”€ dark.toml
â”‚   â””â”€â”€ solarized.toml
â””â”€â”€ keywords.txt                      # Research keywords

~/.cache/arxiv-agent/                 # XDG_CACHE_HOME
â”œâ”€â”€ http/                             # HTTP response cache
â””â”€â”€ models/                           # Local model cache

6. CLI Command Structure
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLI COMMAND HIERARCHY                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

arxiv-agent
â”‚
â”œâ”€â”€ search                            # Search for papers
â”‚   â”œâ”€â”€ <query>                       # arxiv-agent search "transformer attention"
â”‚   â”œâ”€â”€ --limit, -n <int>             # Number of results (default: 10)
â”‚   â”œâ”€â”€ --category, -c <str>          # Filter by arXiv category
â”‚   â”œâ”€â”€ --since <date>                # Papers published after date
â”‚   â”œâ”€â”€ --sort <relevance|date|citations>
â”‚   â””â”€â”€ --save                        # Auto-save results to library
â”‚
â”œâ”€â”€ analyze                           # Deep paper analysis
â”‚   â”œâ”€â”€ <paper_id>                    # arxiv-agent analyze arxiv:2401.12345
â”‚   â”œâ”€â”€ --depth <quick|standard|deep> # Analysis depth
â”‚   â”œâ”€â”€ --sections <list>             # Specific sections to analyze
â”‚   â”œâ”€â”€ --output, -o <format>         # md, json, html
â”‚   â””â”€â”€ --compare <paper_ids>         # Compare multiple papers
â”‚
â”œâ”€â”€ paper2code                        # Generate implementation
â”‚   â”œâ”€â”€ <paper_id>                    # arxiv-agent paper2code arxiv:2401.12345
â”‚   â”œâ”€â”€ --output, -o <path>           # Output directory
â”‚   â”œâ”€â”€ --framework <pytorch|jax|tf>  # Target framework
â”‚   â”œâ”€â”€ --test                        # Generate tests
â”‚   â””â”€â”€ --dry-run                     # Preview without generating
â”‚
â”œâ”€â”€ chat                              # Interactive RAG chat
â”‚   â”œâ”€â”€ <paper_id>                    # Start/resume chat session
â”‚   â”œâ”€â”€ history                       # Show chat history
â”‚   â”‚   â”œâ”€â”€ --session <id>            # Specific session
â”‚   â”‚   â””â”€â”€ --paper <id>              # All sessions for paper
â”‚   â”œâ”€â”€ export <session_id>           # Export chat to markdown
â”‚   â””â”€â”€ clear <session_id>            # Clear session
â”‚
â”œâ”€â”€ digest                            # Daily digest management
â”‚   â”œâ”€â”€ config                        # Configure digest settings
â”‚   â”‚   â”œâ”€â”€ --keywords <list>         # Set research keywords
â”‚   â”‚   â”œâ”€â”€ --time <HH:MM>            # Set delivery time
â”‚   â”‚   â”œâ”€â”€ --papers <int>            # Papers per digest (max 10)
â”‚   â”‚   â””â”€â”€ --categories <list>       # arXiv categories
â”‚   â”œâ”€â”€ run                           # Run digest now
â”‚   â”‚   â””â”€â”€ --dry-run                 # Preview without saving
â”‚   â”œâ”€â”€ schedule                      # Manage scheduling
â”‚   â”‚   â”œâ”€â”€ enable                    # Enable scheduled digests
â”‚   â”‚   â”œâ”€â”€ disable                   # Disable scheduled digests
â”‚   â”‚   â””â”€â”€ status                    # Show schedule status
â”‚   â”œâ”€â”€ show [date]                   # Show digest for date
â”‚   â””â”€â”€ list                          # List all digests
â”‚
â”œâ”€â”€ library                           # Personal library management
â”‚   â”œâ”€â”€ add <paper_id>                # Add paper to library
â”‚   â”‚   â””â”€â”€ --collection <name>       # Add to specific collection
â”‚   â”œâ”€â”€ remove <paper_id>             # Remove from library
â”‚   â”œâ”€â”€ list                          # List all papers
â”‚   â”‚   â”œâ”€â”€ --collection <name>       # Filter by collection
â”‚   â”‚   â”œâ”€â”€ --tag <name>              # Filter by tag
â”‚   â”‚   â””â”€â”€ --sort <date|title|citations>
â”‚   â”œâ”€â”€ collections                   # Manage collections
â”‚   â”‚   â”œâ”€â”€ create <name>             # Create collection
â”‚   â”‚   â”œâ”€â”€ delete <name>             # Delete collection
â”‚   â”‚   â””â”€â”€ list                      # List collections
â”‚   â”œâ”€â”€ tags                          # Manage tags
â”‚   â”‚   â”œâ”€â”€ add <paper_id> <tag>      # Add tag to paper
â”‚   â”‚   â”œâ”€â”€ remove <paper_id> <tag>   # Remove tag
â”‚   â”‚   â””â”€â”€ list                      # List all tags
â”‚   â”œâ”€â”€ export                        # Export library
â”‚   â”‚   â”œâ”€â”€ --format <json|bibtex|md>
â”‚   â”‚   â””â”€â”€ --output <path>
â”‚   â””â”€â”€ import <path>                 # Import papers
â”‚
â”œâ”€â”€ trends                            # Trend discovery
â”‚   â”œâ”€â”€ topics                        # Show trending topics
â”‚   â”‚   â”œâ”€â”€ --category <str>          # Filter by category
â”‚   â”‚   â””â”€â”€ --period <week|month|year>
â”‚   â”œâ”€â”€ papers                        # Show trending papers
â”‚   â”‚   â””â”€â”€ --limit <int>
â”‚   â””â”€â”€ recommend                     # Get recommendations
â”‚       â””â”€â”€ --based-on <library|history|both>
â”‚
â”œâ”€â”€ config                            # Settings management
â”‚   â”œâ”€â”€ show                          # Show all settings
â”‚   â”œâ”€â”€ set <key> <value>             # Set configuration value
â”‚   â”œâ”€â”€ reset                         # Reset to defaults
â”‚   â”œâ”€â”€ theme                         # Theme management
â”‚   â”‚   â”œâ”€â”€ list                      # List available themes
â”‚   â”‚   â”œâ”€â”€ set <name>                # Set theme
â”‚   â”‚   â””â”€â”€ preview <name>            # Preview theme
â”‚   â””â”€â”€ api-keys                      # API key management
â”‚       â”œâ”€â”€ set <service> <key>       # Set API key
â”‚       â”œâ”€â”€ show                      # Show configured keys
â”‚       â””â”€â”€ test                      # Test API connectivity
â”‚
â”œâ”€â”€ daemon                            # Background service
â”‚   â”œâ”€â”€ start                         # Start daemon
â”‚   â”œâ”€â”€ stop                          # Stop daemon
â”‚   â”œâ”€â”€ status                        # Show daemon status
â”‚   â””â”€â”€ logs                          # Show daemon logs
â”‚
â””â”€â”€ --version, -v                     # Show version
    --help, -h                        # Show help
    --verbose                         # Verbose output
    --quiet, -q                       # Minimal output
    --no-color                        # Disable colored output

7. Configuration Schema
# ~/.config/arxiv-agent/config.toml

[
general
]
data_dir = "~/.local/share/arxiv-agent"
cache_dir = "~/.cache/arxiv-agent"
log_level = "INFO"  # DEBUG, INFO, WARNING, ERROR

[
api
]
# LLM Provider Configuration
llm_provider = "anthropic"  # anthropic, ollama, openai
llm_model = "claude-sonnet-4-5-20250514"
llm_model_code = "claude-opus-4-5-20250101"  # For paper2code
llm_fallback = "ollama:llama3.1:8b"
max_tokens = 4096
temperature = 0.7

# External APIs
semantic_scholar_key = ""  # Optional, higher rate limits
crossref_email = ""  # Polite pool access

[
embedding
]
provider = "local"  # local, openai
model = "allenai/specter2"  # or "nomic-embed-text" for Ollama
dimension = 768
batch_size = 32

[
vector_store
]
provider = "chromadb"  # chromadb, qdrant
persist_directory = "${data_dir}/vectors"
collection_prefix = "arxiv_agent"

[
retrieval
]
# Hybrid search configuration
dense_weight = 0.7
sparse_weight = 0.3
top_k = 20
rerank_top_k = 5
use_reranker = true
reranker_model = "cross-encoder/ms-marco-MiniLM-L6-v2"

[
chunking
]
strategy = "section_aware"  # fixed, recursive, section_aware
chunk_size = 768
chunk_overlap = 100
min_chunk_size = 100

[
digest
]
enabled = true
schedule_time = "06:00"
timezone = "Europe/Amsterdam"
max_papers = 10
categories = ["cs.AI", "cs.LG", "cs.CL"]
keywords = ["transformer", "attention", "llm", "agents"]
include_citations = true
min_citation_count = 0

[
chat
]
session_timeout_hours = 24
max_history_messages = 100
context_window_tokens = 8000
summarize_after_messages = 20

[
library
]
auto_download_pdfs = true
pdf_storage_format = "year/month"  # year/month, flat, category
auto_tag = true
tag_confidence_threshold = 0.7

[
trends
]
update_frequency_hours = 24
topic_model = "bertopic"
min_topic_papers = 5

[
ui
]
theme = "default"  # default, dark, solarized, nord
show_progress = true
table_style = "rounded"
max_width = 120
pager = "less"  # less, more, none

[
paper2code
]
default_framework = "pytorch"
generate_tests = true
generate_docs = true
include_examples = true
type_hints = true

8. Learning & Personalization System
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LEARNING & RECOMMENDATION SYSTEM                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           USER INTERACTIONS              â”‚
                    â”‚  â€¢ Searches, Views, Saves, Chats        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           SIGNAL COLLECTION                                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
    â”‚  â”‚  Explicit   â”‚  â”‚  Implicit   â”‚  â”‚   Temporal  â”‚  â”‚  Content    â”‚             â”‚
    â”‚  â”‚  Signals    â”‚  â”‚  Signals    â”‚  â”‚   Signals   â”‚  â”‚  Signals    â”‚             â”‚
    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
    â”‚  â”‚â€¢ Saves      â”‚  â”‚â€¢ Time spent â”‚  â”‚â€¢ Recency    â”‚  â”‚â€¢ Categories â”‚             â”‚
    â”‚  â”‚â€¢ Tags added â”‚  â”‚â€¢ Scroll     â”‚  â”‚â€¢ Frequency  â”‚  â”‚â€¢ Keywords   â”‚             â”‚
    â”‚  â”‚â€¢ Collectionsâ”‚  â”‚â€¢ Re-visits  â”‚  â”‚â€¢ Patterns   â”‚  â”‚â€¢ Authors    â”‚             â”‚
    â”‚  â”‚â€¢ Ratings    â”‚  â”‚â€¢ Chat depth â”‚  â”‚â€¢ Decay      â”‚  â”‚â€¢ Topics     â”‚             â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         PREFERENCE MODELING                                     â”‚
    â”‚                                                                                 â”‚
    â”‚  User Preference Vector:                                                        â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  P = Î± * saved_papers_embed + Î² * viewed_papers_embed +                  â”‚   â”‚
    â”‚  â”‚      Î³ * query_embed + Î´ * category_weights                              â”‚   â”‚
    â”‚  â”‚                                                                          â”‚   â”‚
    â”‚  â”‚  Where:                                                                  â”‚   â”‚
    â”‚  â”‚  â€¢ Î± = 0.4 (strong positive signal)                                      â”‚   â”‚
    â”‚  â”‚  â€¢ Î² = 0.2 (moderate positive signal, time-weighted)                     â”‚   â”‚
    â”‚  â”‚  â€¢ Î³ = 0.3 (search intent signal)                                        â”‚   â”‚
    â”‚  â”‚  â€¢ Î´ = 0.1 (category preference)                                         â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                                 â”‚
    â”‚  Topic Affinity (BERTopic):                                                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  Topic_0: "transformer attention mechanism"     â†’ 0.85                   â”‚   â”‚
    â”‚  â”‚  Topic_1: "reinforcement learning reward"       â†’ 0.45                   â”‚   â”‚
    â”‚  â”‚  Topic_2: "computer vision segmentation"        â†’ 0.12                   â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        RECOMMENDATION GENERATION                                â”‚
    â”‚                                                                                 â”‚
    â”‚  Score(paper) = w1 * cosine_sim(paper_embed, user_pref_embed)                   â”‚
    â”‚               + w2 * topic_alignment_score                                      â”‚
    â”‚               + w3 * citation_normalized_score                                  â”‚
    â”‚               + w4 * recency_score                                              â”‚
    â”‚               + w5 * author_familiarity_score                                   â”‚
    â”‚               - w6 * already_seen_penalty                                       â”‚
    â”‚                                                                                 â”‚
    â”‚  Diversity Injection:                                                           â”‚
    â”‚  â€¢ MMR (Maximal Marginal Relevance) for result diversity                        â”‚
    â”‚  â€¢ Serendipity factor: 10% random exploration                                   â”‚
    â”‚  â€¢ Cross-category discovery                                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           FEEDBACK LOOP                                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  â€¢ Track recommendations â†’ user actions                                  â”‚   â”‚
    â”‚  â”‚  â€¢ Adjust weights based on hit rate                                      â”‚   â”‚
    â”‚  â”‚  â€¢ A/B test different ranking strategies                                 â”‚   â”‚
    â”‚  â”‚  â€¢ Decay old preferences (Î» = 0.95 per week)                             â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

9. Error Handling & Resilience
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ERROR HANDLING STRATEGY                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  Service Call   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  Check Cache    â”‚â”€â”€â”€â”€ Hit â”€â”€â”€â”€â–¶ Return Cached
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ Miss
                                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         RETRY WITH BACKOFF                                   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  @retry(                                                               â”‚  â”‚
    â”‚  â”‚      stop=stop_after_attempt(5),                                       â”‚  â”‚
    â”‚  â”‚      wait=wait_exponential(multiplier=1, min=1, max=60),               â”‚  â”‚
    â”‚  â”‚      retry=retry_if_exception_type((                                   â”‚  â”‚
    â”‚  â”‚          httpx.TimeoutException,                                       â”‚  â”‚
    â”‚  â”‚          httpx.HTTPStatusError,                                        â”‚  â”‚
    â”‚  â”‚          RateLimitError                                                â”‚  â”‚
    â”‚  â”‚      )),                                                               â”‚  â”‚
    â”‚  â”‚      before_sleep=log_retry_attempt                                    â”‚  â”‚
    â”‚  â”‚  )                                                                     â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚                       â”‚
                      Success                   Failure
                           â”‚                       â”‚
                           â–¼                       â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Cache Result   â”‚    â”‚    FALLBACK CHAIN       â”‚
                  â”‚  Return         â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ 1. Try alternate API    â”‚
                                         â”‚    (arXiv â†’ SS â†’ CR)    â”‚
                                         â”‚ 2. Use local cache      â”‚
                                         â”‚    (stale-while-error)  â”‚
                                         â”‚ 3. Use local LLM        â”‚
                                         â”‚    (Ollama fallback)    â”‚
                                         â”‚ 4. Graceful degradation â”‚
                                         â”‚    (partial results)    â”‚
                                         â”‚ 5. User notification    â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         CIRCUIT BREAKER PATTERN                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  States:                                                               â”‚  â”‚
    â”‚  â”‚  â€¢ CLOSED: Normal operation, requests pass through                     â”‚  â”‚
    â”‚  â”‚  â€¢ OPEN: Service unhealthy, requests fail fast (30s timeout)           â”‚  â”‚
    â”‚  â”‚  â€¢ HALF-OPEN: Testing recovery (1 request/10s)                         â”‚  â”‚
    â”‚  â”‚                                                                        â”‚  â”‚
    â”‚  â”‚  Thresholds:                                                           â”‚  â”‚
    â”‚  â”‚  â€¢ failure_threshold: 5 consecutive failures â†’ OPEN                    â”‚  â”‚
    â”‚  â”‚  â€¢ recovery_timeout: 30 seconds                                        â”‚  â”‚
    â”‚  â”‚  â€¢ success_threshold: 3 successes in HALF-OPEN â†’ CLOSED                â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

10. Deployment Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SINGLE-COMMAND INSTALLATION                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Option 1: uv (Recommended - Fastest)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  $ curl -LsSf https://astral.sh/uv/install.sh | sh                             â”‚
    â”‚  $ uv tool install arxiv-agent                                                 â”‚
    â”‚  $ arxiv-agent --version                                                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Option 2: pipx (More Common)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  $ pipx install arxiv-agent                                                    â”‚
    â”‚  $ arxiv-agent --version                                                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Option 3: pip with venv
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  $ python -m venv ~/.arxiv-agent-env                                           â”‚
    â”‚  $ source ~/.arxiv-agent-env/bin/activate                                      â”‚
    â”‚  $ pip install arxiv-agent                                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Post-Installation Setup:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  $ arxiv-agent config api-keys set anthropic <your-key>                        â”‚
    â”‚  $ arxiv-agent digest config --keywords "transformer,attention,llm"            â”‚
    â”‚  $ arxiv-agent digest schedule enable                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            RUNTIME ARCHITECTURE                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Foreground Mode (Interactive):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                                â”‚
    â”‚    User Terminal                                                               â”‚
    â”‚         â”‚                                                                      â”‚
    â”‚         â–¼                                                                      â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
    â”‚    â”‚  Typer CLI  â”‚â”€â”€â”€â”€â”€â–¶â”‚ LangGraph   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Agents    â”‚                   â”‚
    â”‚    â”‚             â”‚      â”‚ Orchestratorâ”‚      â”‚             â”‚                   â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚                                â”‚                    â”‚                          â”‚
    â”‚                                â–¼                    â–¼                          â”‚
    â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
    â”‚                         â”‚   SQLite    â”‚      â”‚   ChromaDB  â”‚                   â”‚
    â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚                                                                                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Background Mode (Daemon):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                               â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚    â”‚                    arxiv-agent daemon                           â”‚        â”‚
    â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚        â”‚
    â”‚    â”‚  â”‚ APScheduler â”‚  â”‚   Digest    â”‚  â”‚   Trend     â”‚              â”‚        â”‚
    â”‚    â”‚  â”‚  (Jobs)     â”‚  â”‚   Worker    â”‚  â”‚  Updater    â”‚              â”‚        â”‚
    â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚        â”‚
    â”‚    â”‚         â”‚                â”‚                â”‚                     â”‚        â”‚
    â”‚    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚        â”‚
    â”‚    â”‚                          â–¼                                      â”‚        â”‚
    â”‚    â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚        â”‚
    â”‚    â”‚                   â”‚   Shared    â”‚                               â”‚        â”‚
    â”‚    â”‚                   â”‚  Resources  â”‚                               â”‚        â”‚
    â”‚    â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚        â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
    â”‚                               â”‚                                               â”‚
    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
    â”‚         â–¼                     â–¼                     â–¼                         â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚    â”‚   SQLite    â”‚      â”‚   ChromaDB  â”‚      â”‚    Logs     â”‚                  â”‚
    â”‚    â”‚   (Shared)  â”‚      â”‚   (Shared)  â”‚      â”‚             â”‚                  â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
    â”‚                                                                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    System Service (Optional):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  # ~/.config/systemd/user/arxiv-agent.service                                  â”‚
    â”‚  [Unit]                                                                        â”‚
    â”‚  Description=ArXiv Agent Background Service                                    â”‚
    â”‚  After=network.target                                                          â”‚
    â”‚                                                                                â”‚
    â”‚  [Service]                                                                     â”‚
    â”‚  Type=simple                                                                   â”‚
    â”‚  ExecStart=%h/.local/bin/arxiv-agent daemon start                              â”‚
    â”‚  Restart=on-failure                                                            â”‚
    â”‚  RestartSec=10                                                                 â”‚
    â”‚                                                                                â”‚
    â”‚  [Install]                                                                     â”‚
    â”‚  WantedBy=default.target                                                       â”‚
    â”‚                                                                                â”‚
    â”‚  $ systemctl --user enable arxiv-agent                                         â”‚
    â”‚  $ systemctl --user start arxiv-agent                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

11. Security Considerations
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            SECURITY ARCHITECTURE                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    API Key Management:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Priority Order:                                                               â”‚
    â”‚  1. System Keyring (keyring library)                                           â”‚
    â”‚     â””â”€ macOS: Keychain                                                         â”‚
    â”‚     â””â”€ Linux: Secret Service (GNOME Keyring, KWallet)                          â”‚
    â”‚     â””â”€ Windows: Windows Credential Locker                                      â”‚
    â”‚  2. Environment Variables                                                      â”‚
    â”‚     â””â”€ ARXIV_AGENT_ANTHROPIC_KEY                                               â”‚
    â”‚     â””â”€ ARXIV_AGENT_SEMANTIC_SCHOLAR_KEY                                        â”‚
    â”‚  3. Config File (NOT recommended for API keys)                                 â”‚
    â”‚     â””â”€ ~/.config/arxiv-agent/config.toml                                       â”‚
    â”‚     â””â”€ chmod 600                                                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Data Protection:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â€¢ SQLite databases: chmod 600                                                 â”‚
    â”‚  â€¢ PDF storage: User-only read/write                                           â”‚
    â”‚  â€¢ No telemetry or data collection                                             â”‚
    â”‚  â€¢ All processing local by default                                             â”‚
    â”‚  â€¢ API calls only for:                                                         â”‚
    â”‚    - arXiv (public papers)                                                     â”‚
    â”‚    - Semantic Scholar (public metadata)                                        â”‚
    â”‚    - Claude API (user-initiated analysis)                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

12. Performance Characteristics
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PERFORMANCE TARGETS                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Operation                          Target Latency       Notes
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Search (10 papers)                 < 3s                 arXiv API rate limited
    Paper Analysis (quick)             < 10s                Haiku model
    Paper Analysis (standard)          < 30s                Sonnet model
    Paper Analysis (deep)              < 2min               Multi-pass Sonnet
    Paper2Code generation              < 5min               Opus model
    RAG Chat (first response)          < 5s                 Cold start
    RAG Chat (subsequent)              < 2s                 Warm context
    Daily Digest (10 papers)           < 10min              Overnight batch
    Library list (1000 papers)         < 500ms              SQLite indexed
    Vector search (100K chunks)        < 100ms              ChromaDB
    Embedding generation               < 50ms/chunk         SPECTER2

    Resource Usage:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Memory (idle)                      ~100MB
    Memory (active analysis)           ~500MB-1GB
    Disk (per paper, full)             ~5MB (PDF + vectors + analysis)
    Disk (1000 papers library)         ~5GB

This architecture provides a robust, maintainable foundation for building the ArxivAgent CLI system. The modular design allows for incremental development, starting with core search/fetch functionality and progressively adding analysis, chat, and learning features.

ğŸš€ ArxivAgent CLI - Implementation Plan
Phase 1: Foundation (Week 1-2)
1.1 Project Setup
# Create project structure
mkdir -p arxiv-agent/{src/arxiv_agent/{cli,agents,core,data,config},tests,docs}
cd arxiv-agent

# Initialize with uv (recommended) or poetry
uv init

pyproject.toml
[
build-system
]
requires = ["hatchling"]
build-backend = "hatchling.build"

[
project
]
name = "arxiv-agent"
version = "0.1.0"
description = "Multi-agent CLI for automated research paper discovery and analysis"
readme = "README.md"
license = "MIT"
requires-python = ">=3.11"
authors = [{ name = "Dev", email = "dev@example.com" }]
keywords = ["arxiv", "research", "ai", "cli", "rag", "llm"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Environment :: Console",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

dependencies = [
    # CLI Framework
    "typer[all]>=0.12.0",
    "rich>=13.7.0",
    "prompt-toolkit>=3.0.43",
    
    # HTTP & APIs
    "httpx>=0.27.0",
    "arxiv>=2.1.0",
    "tenacity>=8.2.3",
    
    # LLM & Embeddings
    "anthropic>=0.39.0",
    "sentence-transformers>=3.0.0",
    "transformers>=4.40.0",
    
    # Vector Store & RAG
    "chromadb>=0.5.0",
    "langchain>=0.3.0",
    "langchain-anthropic>=0.2.0",
    "langgraph>=0.2.0",
    "rank-bm25>=0.2.2",
    
    # PDF Processing
    "pymupdf>=1.24.0",
    "pymupdf4llm>=0.0.10",
    
    # Data & Storage
    "pydantic>=2.7.0",
    "pydantic-settings>=2.2.0",
    "sqlmodel>=0.0.16",
    "diskcache>=5.6.3",
    
    # Scheduling
    "apscheduler>=3.10.4",
    
    # Utilities
    "python-dateutil>=2.9.0",
    "xdg-base-dirs>=6.0.1",
    "keyring>=25.0.0",
    "loguru>=0.7.2",
]

[
project.optional-dependencies
]
dev = [
    "pytest>=8.1.0",
    "pytest-asyncio>=0.23.0",
    "pytest-cov>=5.0.0",
    "responses>=0.25.0",
    "ruff>=0.4.0",
    "mypy>=1.9.0",
    "pre-commit>=3.7.0",
]
local-llm = [
    "ollama>=0.2.0",
]

[
project.scripts
]
arxiv-agent = "arxiv_agent.cli.main:app"

[
tool.hatch.build.targets.wheel
]
packages = ["src/arxiv_agent"]

[
tool.ruff
]
line-length = 100
target-version = "py311"

[
tool.mypy
]
python_version = "3.11"
strict = true

1.2 Configuration System
# src/arxiv_agent/config/settings.py
from pathlib import Path
from typing import Literal
from pydantic import Field, SecretStr
from pydantic_settings import BaseSettings, SettingsConfigDict
from xdg_base_dirs import xdg_config_home, xdg_data_home, xdg_cache_home


class LLMSettings(BaseSettings):
    """LLM provider configuration."""
    provider: Literal["anthropic", "ollama", "openai"] = "anthropic"
    model: str = "claude-sonnet-4-5-20250514"
    model_code: str = "claude-opus-4-5-20250101"  # For paper2code
    fallback_model: str = "ollama:llama3.1:8b"
    max_tokens: int = 4096
    temperature: float = 0.7


class EmbeddingSettings(BaseSettings):
    """Embedding model configuration."""
    provider: Literal["local", "ollama", "openai"] = "local"
    model: str = "allenai/specter2"
    dimension: int = 768
    batch_size: int = 32


class RetrievalSettings(BaseSettings):
    """RAG retrieval configuration."""
    dense_weight: float = 0.7
    sparse_weight: float = 0.3
    top_k: int = 20
    rerank_top_k: int = 5
    use_reranker: bool = True
    reranker_model: str = "cross-encoder/ms-marco-MiniLM-L6-v2"


class ChunkingSettings(BaseSettings):
    """Document chunking configuration."""
    strategy: Literal["fixed", "recursive", "section_aware"] = "section_aware"
    chunk_size: int = 768
    chunk_overlap: int = 100
    min_chunk_size: int = 100


class DigestSettings(BaseSettings):
    """Daily digest configuration."""
    enabled: bool = True
    schedule_time: str = "06:00"
    timezone: str = "UTC"
    max_papers: int = 10
    categories: list[str] = Field(default_factory=lambda: ["cs.AI", "cs.LG", "cs.CL"])
    keywords: list[str] = Field(default_factory=list)
    min_citation_count: int = 0


class ChatSettings(BaseSettings):
    """Chat session configuration."""
    session_timeout_hours: int = 24
    max_history_messages: int = 100
    context_window_tokens: int = 8000
    summarize_after_messages: int = 20


class UISettings(BaseSettings):
    """UI/Theme configuration."""
    theme: str = "default"
    show_progress: bool = True
    table_style: str = "rounded"
    max_width: int = 120


class Settings(BaseSettings):
    """Main application settings."""
    model_config = SettingsConfigDict(
        env_prefix="ARXIV_AGENT_",
        env_nested_delimiter="__",
        toml_file=[xdg_config_home() / "arxiv-agent" / "config.toml"],
    )
    
    # Paths
    data_dir: Path = Field(default_factory=lambda: xdg_data_home() / "arxiv-agent")
    cache_dir: Path = Field(default_factory=lambda: xdg_cache_home() / "arxiv-agent")
    config_dir: Path = Field(default_factory=lambda: xdg_config_home() / "arxiv-agent")
    
    # API Keys (loaded from keyring or env)
    anthropic_api_key: SecretStr | None = None
    semantic_scholar_api_key: SecretStr | None = None
    
    # Nested settings
    llm: LLMSettings = Field(default_factory=LLMSettings)
    embedding: EmbeddingSettings = Field(default_factory=EmbeddingSettings)
    retrieval: RetrievalSettings = Field(default_factory=RetrievalSettings)
    chunking: ChunkingSettings = Field(default_factory=ChunkingSettings)
    digest: DigestSettings = Field(default_factory=DigestSettings)
    chat: ChatSettings = Field(default_factory=ChatSettings)
    ui: UISettings = Field(default_factory=UISettings)
    
    # Logging
    log_level: Literal["DEBUG", "INFO", "WARNING", "ERROR"] = "INFO"
    
    def ensure_directories(self) -> None:
        """Create required directories if they don't exist."""
        for path in [
            self.data_dir,
            self.data_dir / "db",
            self.data_dir / "vectors",
            self.data_dir / "pdfs",
            self.data_dir / "digests",
            self.cache_dir,
            self.config_dir,
        ]:
            path.mkdir(parents=True, exist_ok=True)


# Global settings instance
_settings: Settings | None = None


def get_settings() -> Settings:
    """Get or create settings instance."""
    global _settings
    if _settings is None:
        _settings = Settings()
        _settings.ensure_directories()
    return _settings

1.3 Database Models
# src/arxiv_agent/data/models.py
from datetime import datetime
from typing import Optional
from sqlmodel import Field, SQLModel, Relationship, JSON, Column
from sqlalchemy import Index


class Paper(SQLModel, table=True):
    """Research paper metadata."""
    __tablename__ = "papers"
    
    id: str = Field(primary_key=True)  # arxiv:2401.12345
    title: str
    authors: list[str] = Field(sa_column=Column(JSON), default_factory=list)
    abstract: str
    categories: list[str] = Field(sa_column=Column(JSON), default_factory=list)
    published_date: datetime | None = None
    pdf_path: str | None = None
    pdf_hash: str | None = None
    citation_count: int = 0
    tldr: str | None = None
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)
    
    # Relationships
    analyses: list["Analysis"] = Relationship(back_populates="paper")
    chat_sessions: list["ChatSession"] = Relationship(back_populates="paper")
    
    __table_args__ = (
        Index("idx_papers_published", "published_date"),
    )


class Analysis(SQLModel, table=True):
    """Paper analysis results."""
    __tablename__ = "analyses"
    
    id: int | None = Field(default=None, primary_key=True)
    paper_id: str = Field(foreign_key="papers.id")
    analysis_type: str  # 'summary', 'methodology', 'full', 'code_plan'
    content: dict = Field(sa_column=Column(JSON), default_factory=dict)
    model_used: str | None = None
    token_count: int | None = None
    created_at: datetime = Field(default_factory=datetime.utcnow)
    
    paper: Paper = Relationship(back_populates="analyses")


class Collection(SQLModel, table=True):
    """User-defined paper collections."""
    __tablename__ = "collections"
    
    id: int | None = Field(default=None, primary_key=True)
    name: str = Field(unique=True)
    description: str | None = None
    color: str = "#3B82F6"
    created_at: datetime = Field(default_factory=datetime.utcnow)


class PaperCollection(SQLModel, table=True):
    """Many-to-many relationship between papers and collections."""
    __tablename__ = "paper_collections"
    
    paper_id: str = Field(foreign_key="papers.id", primary_key=True)
    collection_id: int = Field(foreign_key="collections.id", primary_key=True)
    added_at: datetime = Field(default_factory=datetime.utcnow)


class ChatSession(SQLModel, table=True):
    """Chat session metadata."""
    __tablename__ = "chat_sessions"
    
    id: str = Field(primary_key=True)  # UUID
    paper_id: str = Field(foreign_key="papers.id")
    started_at: datetime = Field(default_factory=datetime.utcnow)
    last_active: datetime = Field(default_factory=datetime.utcnow)
    message_count: int = 0
    context_summary: str | None = None
    
    paper: Paper = Relationship(back_populates="chat_sessions")
    messages: list["ChatMessage"] = Relationship(back_populates="session")


class ChatMessage(SQLModel, table=True):
    """Individual chat messages."""
    __tablename__ = "chat_messages"
    
    id: int | None = Field(default=None, primary_key=True)
    session_id: str = Field(foreign_key="chat_sessions.id")
    role: str  # 'user', 'assistant'
    content: str
    retrieved_chunks: list[dict] | None = Field(sa_column=Column(JSON), default=None)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    
    session: ChatSession = Relationship(back_populates="messages")


class Tag(SQLModel, table=True):
    """Paper tags."""
    __tablename__ = "tags"
    
    id: int | None = Field(default=None, primary_key=True)
    name: str = Field(unique=True)
    auto_generated: bool = False


class PaperTag(SQLModel, table=True):
    """Many-to-many relationship between papers and tags."""
    __tablename__ = "paper_tags"
    
    paper_id: str = Field(foreign_key="papers.id", primary_key=True)
    tag_id: int = Field(foreign_key="tags.id", primary_key=True)
    confidence: float | None = None


class ReadingHistory(SQLModel, table=True):
    """User reading/interaction history for learning."""
    __tablename__ = "reading_history"
    
    id: int | None = Field(default=None, primary_key=True)
    paper_id: str = Field(foreign_key="papers.id")
    action: str  # 'viewed', 'analyzed', 'chatted', 'saved', 'code_generated'
    duration_sec: int | None = None
    created_at: datetime = Field(default_factory=datetime.utcnow)


class UserPreference(SQLModel, table=True):
    """User preference key-value store."""
    __tablename__ = "user_preferences"
    
    key: str = Field(primary_key=True)
    value: dict = Field(sa_column=Column(JSON))
    updated_at: datetime = Field(default_factory=datetime.utcnow)

1.4 Database Manager
# src/arxiv_agent/data/storage.py
from contextlib import contextmanager
from pathlib import Path
from typing import Generator

from sqlmodel import Session, SQLModel, create_engine, select
from sqlalchemy import event

from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.models import (
    Paper, Analysis, Collection, ChatSession, ChatMessage,
    Tag, PaperTag, ReadingHistory, UserPreference
)


class DatabaseManager:
    """SQLite database manager with connection pooling."""
    
    def __init__(self, db_path: Path | None = None):
        settings = get_settings()
        self.db_path = db_path or settings.data_dir / "db" / "arxiv-agent.db"
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.engine = create_engine(
            f"sqlite:///{self.db_path}",
            echo=False,
            connect_args={"check_same_thread": False},
        )
        
        # Enable WAL mode for better concurrency
        @event.listens_for(self.engine, "connect")
        def set_sqlite_pragma(dbapi_connection, connection_record):
            cursor = dbapi_connection.cursor()
            cursor.execute("PRAGMA journal_mode=WAL")
            cursor.execute("PRAGMA foreign_keys=ON")
            cursor.execute("PRAGMA busy_timeout=5000")
            cursor.close()
        
        # Create tables
        SQLModel.metadata.create_all(self.engine)
    
    @contextmanager
    def session(self) -> Generator[Session, None, None]:
        """Get a database session."""
        with Session(self.engine) as session:
            try:
                yield session
                session.commit()
            except Exception:
                session.rollback()
                raise
    
    # Paper operations
    def get_paper(self, paper_id: str) -> Paper | None:
        with self.session() as session:
            return session.get(Paper, paper_id)
    
    def save_paper(self, paper: Paper) -> Paper:
        with self.session() as session:
            session.add(paper)
            session.commit()
            session.refresh(paper)
            return paper
    
    def search_papers(
        self,
        query: str | None = None,
        collection_id: int | None = None,
        tag_id: int | None = None,
        limit: int = 50,
        offset: int = 0,
    ) -> list[Paper]:
        with self.session() as session:
            statement = select(Paper)
            
            if query:
                statement = statement.where(
                    Paper.title.contains(query) | Paper.abstract.contains(query)
                )
            
            statement = statement.order_by(Paper.published_date.desc())
            statement = statement.offset(offset).limit(limit)
            
            return list(session.exec(statement).all())
    
    # Analysis operations
    def save_analysis(self, analysis: Analysis) -> Analysis:
        with self.session() as session:
            session.add(analysis)
            session.commit()
            session.refresh(analysis)
            return analysis
    
    def get_latest_analysis(self, paper_id: str, analysis_type: str) -> Analysis | None:
        with self.session() as session:
            statement = (
                select(Analysis)
                .where(Analysis.paper_id == paper_id)
                .where(Analysis.analysis_type == analysis_type)
                .order_by(Analysis.created_at.desc())
                .limit(1)
            )
            return session.exec(statement).first()
    
    # Chat operations
    def get_or_create_chat_session(self, paper_id: str) -> ChatSession:
        import uuid
        from datetime import datetime, timedelta
        
        settings = get_settings()
        cutoff = datetime.utcnow() - timedelta(hours=settings.chat.session_timeout_hours)
        
        with self.session() as session:
            # Find recent active session
            statement = (
                select(ChatSession)
                .where(ChatSession.paper_id == paper_id)
                .where(ChatSession.last_active > cutoff)
                .order_by(ChatSession.last_active.desc())
                .limit(1)
            )
            existing = session.exec(statement).first()
            
            if existing:
                existing.last_active = datetime.utcnow()
                session.add(existing)
                return existing
            
            # Create new session
            new_session = ChatSession(
                id=str(uuid.uuid4()),
                paper_id=paper_id,
            )
            session.add(new_session)
            session.commit()
            session.refresh(new_session)
            return new_session
    
    def add_chat_message(
        self,
        session_id: str,
        role: str,
        content: str,
        retrieved_chunks: list[dict] | None = None,
    ) -> ChatMessage:
        with self.session() as session:
            message = ChatMessage(
                session_id=session_id,
                role=role,
                content=content,
                retrieved_chunks=retrieved_chunks,
            )
            session.add(message)
            
            # Update session
            chat_session = session.get(ChatSession, session_id)
            if chat_session:
                chat_session.message_count += 1
                chat_session.last_active = message.created_at
                session.add(chat_session)
            
            session.commit()
            session.refresh(message)
            return message
    
    def get_chat_history(self, session_id: str, limit: int = 100) -> list[ChatMessage]:
        with self.session() as session:
            statement = (
                select(ChatMessage)
                .where(ChatMessage.session_id == session_id)
                .order_by(ChatMessage.created_at.asc())
                .limit(limit)
            )
            return list(session.exec(statement).all())
    
    # Reading history for learning
    def record_interaction(
        self,
        paper_id: str,
        action: str,
        duration_sec: int | None = None,
    ) -> None:
        with self.session() as session:
            history = ReadingHistory(
                paper_id=paper_id,
                action=action,
                duration_sec=duration_sec,
            )
            session.add(history)


# Global instance
_db: DatabaseManager | None = None


def get_db() -> DatabaseManager:
    """Get or create database manager instance."""
    global _db
    if _db is None:
        _db = DatabaseManager()
    return _db

Phase 2: Core Services (Week 2-3)
2.1 API Client Manager
# src/arxiv_agent/core/api_client.py
import asyncio
from datetime import datetime, timedelta
from typing import Any

import arxiv
import httpx
from diskcache import Cache
from loguru import logger
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.models import Paper


class RateLimiter:
    """Token bucket rate limiter."""
    
    def __init__(self, rate: float, per: float = 1.0):
        self.rate = rate
        self.per = per
        self.tokens = rate
        self.last_update = datetime.now()
        self._lock = asyncio.Lock()
    
    async def acquire(self) -> None:
        async with self._lock:
            now = datetime.now()
            elapsed = (now - self.last_update).total_seconds()
            self.tokens = min(self.rate, self.tokens + elapsed * (self.rate / self.per))
            self.last_update = now
            
            if self.tokens < 1:
                wait_time = (1 - self.tokens) * (self.per / self.rate)
                await asyncio.sleep(wait_time)
                self.tokens = 0
            else:
                self.tokens -= 1


class APIClientManager:
    """Unified API client with caching and rate limiting."""
    
    def __init__(self):
        settings = get_settings()
        
        # HTTP client
        self.http = httpx.AsyncClient(
            timeout=30.0,
            headers={"User-Agent": "arxiv-agent/0.1.0 (research tool)"},
        )
        
        # arXiv client
        self.arxiv_client = arxiv.Client(
            page_size=100,
            delay_seconds=3,  # Required by arXiv
            num_retries=3,
        )
        
        # Rate limiters
        self.arxiv_limiter = RateLimiter(rate=1, per=3)  # 1 req per 3 seconds
        self.semantic_scholar_limiter = RateLimiter(rate=1, per=1)  # 1 req/sec
        
        # Cache
        self.cache = Cache(str(settings.cache_dir / "api_responses"))
        self.cache_ttl = 86400  # 24 hours
        
        # API keys
        self.ss_api_key = (
            settings.semantic_scholar_api_key.get_secret_value()
            if settings.semantic_scholar_api_key
            else None
        )
    
    def _cache_key(self, prefix: str, *args: Any) -> str:
        return f"{prefix}:{':'.join(str(a) for a in args)}"
    
    # arXiv API
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=3, max=30),
        retry=retry_if_exception_type((httpx.TimeoutException, arxiv.ArxivError)),
    )
    async def search_arxiv(
        self,
        query: str,
        max_results: int = 10,
        sort_by: arxiv.SortCriterion = arxiv.SortCriterion.SubmittedDate,
        categories: list[str] | None = None,
        date_from: datetime | None = None,
    ) -> list[Paper]:
        """Search arXiv for papers."""
        await self.arxiv_limiter.acquire()
        
        # Build query
        parts = [query]
        if categories:
            cat_query = " OR ".join(f"cat:{cat}" for cat in categories)
            parts.append(f"({cat_query})")
        
        full_query = " AND ".join(parts)
        
        if date_from:
            # Add date filter
            date_str = date_from.strftime("%Y%m%d")
            full_query = f"{full_query} AND submittedDate:[{date_str}0000 TO 99991231235959]"
        
        search = arxiv.Search(
            query=full_query,
            max_results=max_results,
            sort_by=sort_by,
        )
        
        papers = []
        for result in self.arxiv_client.results(search):
            paper = Paper(
                id=f"arxiv:{result.entry_id.split('/')[-1]}",
                title=result.title,
                authors=[a.name for a in result.authors],
                abstract=result.summary,
                categories=list(result.categories),
                published_date=result.published,
                pdf_path=None,
            )
            papers.append(paper)
        
        return papers
    
    async def download_pdf(self, paper: Paper, output_dir: str) -> str:
        """Download PDF for a paper."""
        from pathlib import Path
        
        arxiv_id = paper.id.replace("arxiv:", "")
        
        # Check cache
        cache_key = self._cache_key("pdf_path", paper.id)
        if cached := self.cache.get(cache_key):
            if Path(cached).exists():
                return cached
        
        search = arxiv.Search(id_list=[arxiv_id])
        result = next(self.arxiv_client.results(search))
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        filename = f"arxiv_{arxiv_id.replace('.', '_')}.pdf"
        filepath = output_path / filename
        
        result.download_pdf(dirpath=str(output_path), filename=filename)
        
        self.cache.set(cache_key, str(filepath), expire=self.cache_ttl * 30)
        return str(filepath)
    
    # Semantic Scholar API
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=30),
        retry=retry_if_exception_type(httpx.HTTPStatusError),
    )
    async def enrich_with_semantic_scholar(self, paper: Paper) -> Paper:
        """Enrich paper with Semantic Scholar data."""
        cache_key = self._cache_key("ss", paper.id)
        if cached := self.cache.get(cache_key):
            paper.citation_count = cached.get("citationCount", 0)
            paper.tldr = cached.get("tldr", {}).get("text")
            return paper
        
        await self.semantic_scholar_limiter.acquire()
        
        arxiv_id = paper.id.replace("arxiv:", "")
        url = f"https://api.semanticscholar.org/graph/v1/paper/arXiv:{arxiv_id}"
        params = {"fields": "citationCount,tldr,influentialCitationCount"}
        
        headers = {}
        if self.ss_api_key:
            headers["x-api-key"] = self.ss_api_key
        
        try:
            response = await self.http.get(url, params=params, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            paper.citation_count = data.get("citationCount", 0)
            if tldr := data.get("tldr"):
                paper.tldr = tldr.get("text")
            
            self.cache.set(cache_key, data, expire=self.cache_ttl)
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                logger.debug(f"Paper {paper.id} not found in Semantic Scholar")
            else:
                raise
        
        return paper
    
    async def get_trending_papers(
        self,
        categories: list[str],
        days: int = 7,
        limit: int = 20,
    ) -> list[Paper]:
        """Get trending papers based on citation velocity."""
        # Search recent papers
        date_from = datetime.now() - timedelta(days=days)
        papers = await self.search_arxiv(
            query="*",
            max_results=100,
            categories=categories,
            date_from=date_from,
        )
        
        # Enrich with citation data
        enriched = []
        for paper in papers:
            try:
                enriched.append(await self.enrich_with_semantic_scholar(paper))
            except Exception as e:
                logger.warning(f"Failed to enrich {paper.id}: {e}")
                enriched.append(paper)
        
        # Sort by citations
        enriched.sort(key=lambda p: p.citation_count, reverse=True)
        return enriched[:limit]
    
    async def close(self) -> None:
        """Close HTTP client."""
        await self.http.aclose()


# Global instance
_client: APIClientManager | None = None


def get_api_client() -> APIClientManager:
    """Get or create API client instance."""
    global _client
    if _client is None:
        _client = APIClientManager()
    return _client

2.2 PDF Processing Service
# src/arxiv_agent/core/pdf_processor.py
import hashlib
import re
from dataclasses import dataclass
from pathlib import Path

import pymupdf4llm
from loguru import logger

from arxiv_agent.config.settings import get_settings


@dataclass
class Section:
    """Represents a paper section."""
    name: str
    content: str
    page_start: int
    page_end: int


@dataclass
class ProcessedPaper:
    """Fully processed paper content."""
    full_text: str
    markdown: str
    sections: list[Section]
    page_count: int
    pdf_hash: str


class PDFProcessor:
    """PDF processing with section awareness."""
    
    SECTION_PATTERNS = [
        r"^#{1,3}\s*(abstract|introduction|related\s*work|background|"
        r"methodology|methods?|approach|experiments?|results?|"
        r"discussion|conclusion|references?|appendix)",
        r"^\d+\.?\s*(abstract|introduction|related\s*work|background|"
        r"methodology|methods?|approach|experiments?|results?|"
        r"discussion|conclusion|references?|appendix)",
    ]
    
    def __init__(self):
        self.settings = get_settings()
    
    def compute_hash(self, pdf_path: str) -> str:
        """Compute SHA256 hash of PDF file."""
        hasher = hashlib.sha256()
        with open(pdf_path, "rb") as f:
            for chunk in iter(lambda: f.read(8192), b""):
                hasher.update(chunk)
        return hasher.hexdigest()
    
    def extract_markdown(self, pdf_path: str) -> str:
        """Extract markdown from PDF using PyMuPDF4LLM."""
        try:
            md_text = pymupdf4llm.to_markdown(
                pdf_path,
                page_chunks=False,
                write_images=False,
            )
            return md_text
        except Exception as e:
            logger.error(f"Failed to extract markdown: {e}")
            raise
    
    def extract_sections(self, markdown: str) -> list[Section]:
        """Extract sections from markdown content."""
        sections = []
        current_section = "preamble"
        current_content = []
        current_page = 1
        
        for line in markdown.split("\n"):
            # Check for section headers
            section_match = None
            for pattern in self.SECTION_PATTERNS:
                if match := re.match(pattern, line.lower().strip()):
                    section_match = match.group(1).strip()
                    break
            
            if section_match:
                # Save previous section
                if current_content:
                    sections.append(Section(
                        name=current_section,
                        content="\n".join(current_content),
                        page_start=current_page,
                        page_end=current_page,
                    ))
                current_section = section_match
                current_content = [line]
            else:
                current_content.append(line)
        
        # Save final section
        if current_content:
            sections.append(Section(
                name=current_section,
                content="\n".join(current_content),
                page_start=current_page,
                page_end=current_page,
            ))
        
        return sections
    
    def process(self, pdf_path: str) -> ProcessedPaper:
        """Fully process a PDF file."""
        path = Path(pdf_path)
        if not path.exists():
            raise FileNotFoundError(f"PDF not found: {pdf_path}")
        
        # Compute hash for deduplication
        pdf_hash = self.compute_hash(pdf_path)
        
        # Extract content
        markdown = self.extract_markdown(pdf_path)
        
        # Get page count
        import fitz
        doc = fitz.open(pdf_path)
        page_count = len(doc)
        doc.close()
        
        # Extract sections
        sections = self.extract_sections(markdown)
        
        # Plain text extraction
        full_text = re.sub(r"\s+", " ", markdown)
        full_text = re.sub(r"[#*_`]", "", full_text)
        
        return ProcessedPaper(
            full_text=full_text,
            markdown=markdown,
            sections=sections,
            page_count=page_count,
            pdf_hash=pdf_hash,
        )


def get_pdf_processor() -> PDFProcessor:
    """Get PDF processor instance."""
    return PDFProcessor()

2.3 Embedding & Vector Store Service
# src/arxiv_agent/core/vector_store.py
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import chromadb
from chromadb.config import Settings as ChromaSettings
from loguru import logger
from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi

from arxiv_agent.config.settings import get_settings


@dataclass
class Chunk:
    """Document chunk with metadata."""
    id: str
    content: str
    paper_id: str
    section: str
    chunk_index: int
    embedding: list[float] | None = None


@dataclass
class RetrievalResult:
    """Search result with score."""
    chunk: Chunk
    score: float
    source: str  # 'dense', 'sparse', 'hybrid'


class EmbeddingService:
    """Manages text embeddings."""
    
    def __init__(self):
        settings = get_settings()
        self.model = SentenceTransformer(settings.embedding.model)
        self.dimension = settings.embedding.dimension
        self.batch_size = settings.embedding.batch_size
    
    def embed(self, texts: list[str]) -> list[list[float]]:
        """Generate embeddings for texts."""
        embeddings = self.model.encode(
            texts,
            batch_size=self.batch_size,
            show_progress_bar=False,
            convert_to_numpy=True,
        )
        return embeddings.tolist()
    
    def embed_query(self, query: str) -> list[float]:
        """Generate embedding for a single query."""
        return self.embed([query])[0]


class VectorStore:
    """ChromaDB-based vector store with hybrid search."""
    
    def __init__(self):
        settings = get_settings()
        
        persist_dir = str(settings.data_dir / "vectors" / "chroma")
        Path(persist_dir).mkdir(parents=True, exist_ok=True)
        
        self.client = chromadb.PersistentClient(
            path=persist_dir,
            settings=ChromaSettings(
                anonymized_telemetry=False,
                allow_reset=True,
            ),
        )
        
        self.embedding_service = EmbeddingService()
        
        # Collections
        self.chunks_collection = self.client.get_or_create_collection(
            name="paper_chunks",
            metadata={"hnsw:space": "cosine"},
        )
        
        self.papers_collection = self.client.get_or_create_collection(
            name="paper_summaries",
            metadata={"hnsw:space": "cosine"},
        )
        
        # BM25 index (rebuilt on demand)
        self._bm25_index: BM25Okapi | None = None
        self._bm25_docs: list[str] = []
        self._bm25_ids: list[str] = []
    
    def add_chunks(self, chunks: list[Chunk]) -> None:
        """Add document chunks to the vector store."""
        if not chunks:
            return
        
        # Generate embeddings
        texts = [c.content for c in chunks]
        embeddings = self.embedding_service.embed(texts)
        
        # Prepare for ChromaDB
        ids = [c.id for c in chunks]
        metadatas = [
            {
                "paper_id": c.paper_id,
                "section": c.section,
                "chunk_index": c.chunk_index,
            }
            for c in chunks
        ]
        
        self.chunks_collection.add(
            ids=ids,
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas,
        )
        
        # Invalidate BM25 index
        self._bm25_index = None
        
        logger.info(f"Added {len(chunks)} chunks to vector store")
    
    def _build_bm25_index(self) -> None:
        """Build BM25 index from all documents."""
        # Get all documents
        results = self.chunks_collection.get(include=["documents"])
        
        if not results["documents"]:
            return
        
        self._bm25_docs = results["documents"]
        self._bm25_ids = results["ids"]
        
        # Tokenize
        tokenized = [doc.lower().split() for doc in self._bm25_docs]
        self._bm25_index = BM25Okapi(tokenized)
    
    def dense_search(
        self,
        query: str,
        paper_id: str | None = None,
        k: int = 20,
    ) -> list[RetrievalResult]:
        """Semantic search using embeddings."""
        query_embedding = self.embedding_service.embed_query(query)
        
        where_filter = {"paper_id": paper_id} if paper_id else None
        
        results = self.chunks_collection.query(
            query_embeddings=[query_embedding],
            n_results=k,
            where=where_filter,
            include=["documents", "metadatas", "distances"],
        )
        
        retrieval_results = []
        for i, doc_id in enumerate(results["ids"][0]):
            chunk = Chunk(
                id=doc_id,
                content=results["documents"][0][i],
                paper_id=results["metadatas"][0][i]["paper_id"],
                section=results["metadatas"][0][i]["section"],
                chunk_index=results["metadatas"][0][i]["chunk_index"],
            )
            # Convert distance to similarity score
            score = 1 - results["distances"][0][i]
            retrieval_results.append(RetrievalResult(
                chunk=chunk,
                score=score,
                source="dense",
            ))
        
        return retrieval_results
    
    def sparse_search(
        self,
        query: str,
        paper_id: str | None = None,
        k: int = 20,
    ) -> list[RetrievalResult]:
        """BM25 keyword search."""
        if self._bm25_index is None:
            self._build_bm25_index()
        
        if not self._bm25_index:
            return []
        
        tokenized_query = query.lower().split()
        scores = self._bm25_index.get_scores(tokenized_query)
        
        # Get top-k indices
        top_indices = sorted(
            range(len(scores)),
            key=lambda i: scores[i],
            reverse=True,
        )[:k * 2]  # Get more for filtering
        
        results = []
        for idx in top_indices:
            doc_id = self._bm25_ids[idx]
            doc = self._bm25_docs[idx]
            score = scores[idx]
            
            # Get metadata
            meta = self.chunks_collection.get(
                ids=[doc_id],
                include=["metadatas"],
            )["metadatas"][0]
            
            if paper_id and meta["paper_id"] != paper_id:
                continue
            
            chunk = Chunk(
                id=doc_id,
                content=doc,
                paper_id=meta["paper_id"],
                section=meta["section"],
                chunk_index=meta["chunk_index"],
            )
            results.append(RetrievalResult(
                chunk=chunk,
                score=score,
                source="sparse",
            ))
            
            if len(results) >= k:
                break
        
        return results
    
    def hybrid_search(
        self,
        query: str,
        paper_id: str | None = None,
        k: int = 20,
        dense_weight: float = 0.7,
    ) -> list[RetrievalResult]:
        """Hybrid search combining dense and sparse retrieval."""
        settings = get_settings()
        
        # Get results from both methods
        dense_results = self.dense_search(query, paper_id, k * 2)
        sparse_results = self.sparse_search(query, paper_id, k * 2)
        
        # Reciprocal Rank Fusion
        rrf_scores: dict[str, float] = {}
        chunk_map: dict[str, Chunk] = {}
        
        k_constant = 60  # RRF constant
        
        for rank, result in enumerate(dense_results):
            chunk_id = result.chunk.id
            rrf_scores[chunk_id] = rrf_scores.get(chunk_id, 0) + dense_weight / (k_constant + rank + 1)
            chunk_map[chunk_id] = result.chunk
        
        sparse_weight = 1 - dense_weight
        for rank, result in enumerate(sparse_results):
            chunk_id = result.chunk.id
            rrf_scores[chunk_id] = rrf_scores.get(chunk_id, 0) + sparse_weight / (k_constant + rank + 1)
            chunk_map[chunk_id] = result.chunk
        
        # Sort by RRF score
        sorted_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)
        
        return [
            RetrievalResult(
                chunk=chunk_map[chunk_id],
                score=rrf_scores[chunk_id],
                source="hybrid",
            )
            for chunk_id in sorted_ids[:k]
        ]
    
    def delete_paper(self, paper_id: str) -> None:
        """Delete all chunks for a paper."""
        self.chunks_collection.delete(where={"paper_id": paper_id})
        self._bm25_index = None  # Invalidate


# Global instance
_vector_store: VectorStore | None = None


def get_vector_store() -> VectorStore:
    """Get or create vector store instance."""
    global _vector_store
    if _vector_store is None:
        _vector_store = VectorStore()
    return _vector_store

2.4 LLM Service
# src/arxiv_agent/core/llm_service.py
from dataclasses import dataclass
from typing import Any, AsyncGenerator

from anthropic import Anthropic, AsyncAnthropic
from loguru import logger

from arxiv_agent.config.settings import get_settings


@dataclass
class LLMResponse:
    """LLM response with metadata."""
    content: str
    model: str
    input_tokens: int
    output_tokens: int
    stop_reason: str


class LLMService:
    """Manages LLM interactions with fallback support."""
    
    def __init__(self):
        settings = get_settings()
        
        api_key = (
            settings.anthropic_api_key.get_secret_value()
            if settings.anthropic_api_key
            else None
        )
        
        if not api_key:
            raise ValueError("Anthropic API key not configured")
        
        self.sync_client = Anthropic(api_key=api_key)
        self.async_client = AsyncAnthropic(api_key=api_key)
        
        self.default_model = settings.llm.model
        self.code_model = settings.llm.model_code
        self.max_tokens = settings.llm.max_tokens
        self.temperature = settings.llm.temperature
    
    async def generate(
        self,
        prompt: str,
        system: str | None = None,
        model: str | None = None,
        max_tokens: int | None = None,
        temperature: float | None = None,
    ) -> LLMResponse:
        """Generate a response from the LLM."""
        model = model or self.default_model
        max_tokens = max_tokens or self.max_tokens
        temperature = temperature if temperature is not None else self.temperature
        
        messages = [{"role": "user", "content": prompt}]
        
        try:
            response = await self.async_client.messages.create(
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                system=system or "",
                messages=messages,
            )
            
            return LLMResponse(
                content=response.content[0].text,
                model=model,
                input_tokens=response.usage.input_tokens,
                output_tokens=response.usage.output_tokens,
                stop_reason=response.stop_reason,
            )
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            raise
    
    async def generate_stream(
        self,
        prompt: str,
        system: str | None = None,
        model: str | None = None,
        max_tokens: int | None = None,
    ) -> AsyncGenerator[str, None]:
        """Stream a response from the LLM."""
        model = model or self.default_model
        max_tokens = max_tokens or self.max_tokens
        
        messages = [{"role": "user", "content": prompt}]
        
        async with self.async_client.messages.stream(
            model=model,
            max_tokens=max_tokens,
            system=system or "",
            messages=messages,
        ) as stream:
            async for text in stream.text_stream:
                yield text
    
    async def generate_structured(
        self,
        prompt: str,
        output_schema: dict[str, Any],
        system: str | None = None,
        model: str | None = None,
    ) -> dict[str, Any]:
        """Generate structured output using tool use."""
        import json
        
        model = model or self.default_model
        
        tool = {
            "name": "output_structured_data",
            "description": "Output the analysis in structured format",
            "input_schema": output_schema,
        }
        
        response = await self.async_client.messages.create(
            model=model,
            max_tokens=self.max_tokens,
            system=system or "",
            messages=[{"role": "user", "content": prompt}],
            tools=[tool],
            tool_choice={"type": "tool", "name": "output_structured_data"},
        )
        
        for block in response.content:
            if block.type == "tool_use":
                return block.input
        
        raise ValueError("No structured output generated")


# Global instance
_llm_service: LLMService | None = None


def get_llm_service() -> LLMService:
    """Get or create LLM service instance."""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMService()
    return _llm_service

Phase 3: Agents (Week 3-4)
3.1 Agent State & Orchestrator
# src/arxiv_agent/agents/state.py
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Literal

from arxiv_agent.data.models import Paper


@dataclass
class AgentState:
    """Shared state for multi-agent workflow."""
    
    # Input
    task: str = ""
    task_type: Literal["search", "analyze", "chat", "digest", "paper2code", "trends"] = "search"
    paper_id: str | None = None
    query: str | None = None
    
    # Papers
    papers: list[Paper] = field(default_factory=list)
    current_paper: Paper | None = None
    
    # Analysis
    analysis: dict[str, Any] = field(default_factory=dict)
    
    # Chat
    chat_history: list[dict[str, str]] = field(default_factory=list)
    retrieved_chunks: list[dict] = field(default_factory=list)
    
    # Code generation
    code_plan: dict[str, Any] | None = None
    generated_code: dict[str, str] = field(default_factory=dict)
    
    # Status
    status: Literal["pending", "running", "completed", "failed"] = "pending"
    current_step: str = ""
    errors: list[str] = field(default_factory=list)
    
    # Metadata
    started_at: datetime = field(default_factory=datetime.utcnow)
    completed_at: datetime | None = None

# src/arxiv_agent/agents/orchestrator.py
from typing import Literal

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver

from arxiv_agent.agents.state import AgentState
from arxiv_agent.agents.fetcher import FetcherAgent
from arxiv_agent.agents.analyzer import AnalyzerAgent
from arxiv_agent.agents.rag_chat import RAGChatAgent
from arxiv_agent.agents.librarian import LibrarianAgent
from arxiv_agent.agents.trend_analyst import TrendAnalystAgent
from arxiv_agent.config.settings import get_settings


class Orchestrator:
    """LangGraph-based multi-agent orchestrator."""
    
    def __init__(self):
        settings = get_settings()
        
        # Initialize agents
        self.fetcher = FetcherAgent()
        self.analyzer = AnalyzerAgent()
        self.rag_chat = RAGChatAgent()
        self.librarian = LibrarianAgent()
        self.trend_analyst = TrendAnalystAgent()
        
        # Setup checkpointer
        checkpoint_path = settings.data_dir / "db" / "checkpoints.db"
        self.checkpointer = SqliteSaver(str(checkpoint_path))
        
        # Build workflow
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """Build the LangGraph workflow."""
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("route", self._route)
        workflow.add_node("fetch", self.fetcher.run)
        workflow.add_node("analyze", self.analyzer.run)
        workflow.add_node("chat", self.rag_chat.run)
        workflow.add_node("library", self.librarian.run)
        workflow.add_node("trends", self.trend_analyst.run)
        workflow.add_node("finalize", self._finalize)
        
        # Set entry point
        workflow.set_entry_point("route")
        
        # Add conditional edges from router
        workflow.add_conditional_edges(
            "route",
            self._get_next_node,
            {
                "fetch": "fetch",
                "analyze": "analyze",
                "chat": "chat",
                "library": "library",
                "trends": "trends",
                "end": END,
            },
        )
        
        # Add edges to finalize
        for node in ["fetch", "analyze", "chat", "library", "trends"]:
            workflow.add_edge(node, "finalize")
        
        workflow.add_edge("finalize", END)
        
        return workflow.compile(checkpointer=self.checkpointer)
    
    def _route(self, state: AgentState) -> AgentState:
        """Route task to appropriate agent."""
        state.status = "running"
        state.current_step = "routing"
        return state
    
    def _get_next_node(
        self, state: AgentState
    ) -> Literal["fetch", "analyze", "chat", "library", "trends", "end"]:
        """Determine next node based on task type."""
        task_mapping = {
            "search": "fetch",
            "analyze": "analyze",
            "chat": "chat",
            "digest": "fetch",  # Digest starts with fetch
            "paper2code": "analyze",  # Paper2code is specialized analysis
            "trends": "trends",
            "library": "library",
        }
        return task_mapping.get(state.task_type, "end")
    
    def _finalize(self, state: AgentState) -> AgentState:
        """Finalize workflow execution."""
        from datetime import datetime
        
        state.status = "completed" if not state.errors else "failed"
        state.completed_at = datetime.utcnow()
        state.current_step = "completed"
        return state
    
    async def run(
        self,
        task_type: str,
        paper_id: str | None = None,
        query: str | None = None,
        thread_id: str | None = None,
    ) -> AgentState:
        """Execute workflow."""
        import uuid
        
        initial_state = AgentState(
            task=f"{task_type}:{paper_id or query}",
            task_type=task_type,
            paper_id=paper_id,
            query=query,
        )
        
        config = {
            "configurable": {
                "thread_id": thread_id or str(uuid.uuid4()),
            }
        }
        
        result = await self.workflow.ainvoke(initial_state, config)
        return result


# Global instance
_orchestrator: Orchestrator | None = None


def get_orchestrator() -> Orchestrator:
    """Get or create orchestrator instance."""
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = Orchestrator()
    return _orchestrator

3.2 Fetcher Agent
# src/arxiv_agent/agents/fetcher.py
from datetime import datetime, timedelta
from loguru import logger

from arxiv_agent.agents.state import AgentState
from arxiv_agent.core.api_client import get_api_client
from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.storage import get_db


class FetcherAgent:
    """Agent responsible for fetching papers from external APIs."""
    
    def __init__(self):
        self.api_client = get_api_client()
        self.settings = get_settings()
        self.db = get_db()
    
    async def run(self, state: AgentState) -> AgentState:
        """Execute fetcher agent."""
        state.current_step = "fetching"
        
        try:
            if state.task_type == "search":
                await self._search_papers(state)
            elif state.task_type == "digest":
                await self._fetch_digest_papers(state)
            elif state.paper_id:
                await self._fetch_single_paper(state)
        except Exception as e:
            logger.error(f"Fetcher error: {e}")
            state.errors.append(f"Fetch failed: {str(e)}")
        
        return state
    
    async def _search_papers(self, state: AgentState) -> None:
        """Search for papers matching query."""
        if not state.query:
            state.errors.append("No search query provided")
            return
        
        papers = await self.api_client.search_arxiv(
            query=state.query,
            max_results=10,
            categories=self.settings.digest.categories or None,
        )
        
        # Enrich with citations
        enriched = []
        for paper in papers:
            try:
                enriched.append(
                    await self.api_client.enrich_with_semantic_scholar(paper)
                )
            except Exception as e:
                logger.warning(f"Failed to enrich {paper.id}: {e}")
                enriched.append(paper)
        
        state.papers = enriched
        
        # Save to database
        for paper in enriched:
            self.db.save_paper(paper)
    
    async def _fetch_digest_papers(self, state: AgentState) -> None:
        """Fetch papers for daily digest."""
        date_from = datetime.now() - timedelta(days=1)
        
        # Build query from keywords
        keywords = self.settings.digest.keywords
        query = " OR ".join(keywords) if keywords else "*"
        
        papers = await self.api_client.search_arxiv(
            query=query,
            max_results=self.settings.digest.max_papers * 2,
            categories=self.settings.digest.categories,
            date_from=date_from,
        )
        
        # Enrich and rank
        enriched = []
        for paper in papers:
            try:
                enriched.append(
                    await self.api_client.enrich_with_semantic_scholar(paper)
                )
            except Exception:
                enriched.append(paper)
        
        # Filter by citation count if configured
        if self.settings.digest.min_citation_count > 0:
            enriched = [
                p for p in enriched
                if p.citation_count >= self.settings.digest.min_citation_count
            ]
        
        # Sort by citations and take top N
        enriched.sort(key=lambda p: p.citation_count, reverse=True)
        state.papers = enriched[:self.settings.digest.max_papers]
        
        # Save papers
        for paper in state.papers:
            self.db.save_paper(paper)
    
    async def _fetch_single_paper(self, state: AgentState) -> None:
        """Fetch a single paper by ID."""
        # Check database first
        existing = self.db.get_paper(state.paper_id)
        if existing:
            state.current_paper = existing
            state.papers = [existing]
            return
        
        # Fetch from API
        arxiv_id = state.paper_id.replace("arxiv:", "")
        papers = await self.api_client.search_arxiv(
            query=f"id:{arxiv_id}",
            max_results=1,
        )
        
        if papers:
            paper = await self.api_client.enrich_with_semantic_scholar(papers[0])
            self.db.save_paper(paper)
            state.current_paper = paper
            state.papers = [paper]
        else:
            state.errors.append(f"Paper not found: {state.paper_id}")

3.3 Analyzer Agent
# src/arxiv_agent/agents/analyzer.py
from pathlib import Path
from loguru import logger

from arxiv_agent.agents.state import AgentState
from arxiv_agent.core.api_client import get_api_client
from arxiv_agent.core.pdf_processor import get_pdf_processor
from arxiv_agent.core.vector_store import get_vector_store, Chunk
from arxiv_agent.core.llm_service import get_llm_service
from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.storage import get_db
from arxiv_agent.data.models import Analysis


ANALYSIS_SYSTEM_PROMPT = """You are an expert research paper analyst. 
Your task is to provide comprehensive analysis of academic papers.
Be thorough, accurate, and cite specific sections when relevant.
Focus on methodology, key findings, limitations, and practical implications."""

ANALYSIS_PROMPT_TEMPLATE = """Analyze the following research paper:

Title: {title}
Authors: {authors}

Content:
{content}

Provide a comprehensive analysis including:
1. Main contribution and novelty
2. Methodology and approach
3. Key findings and results
4. Limitations and future work
5. Practical applications
6. Related work connections"""


class AnalyzerAgent:
    """Agent for deep paper analysis."""
    
    def __init__(self):
        self.api_client = get_api_client()
        self.pdf_processor = get_pdf_processor()
        self.vector_store = get_vector_store()
        self.llm = get_llm_service()
        self.settings = get_settings()
        self.db = get_db()
    
    async def run(self, state: AgentState) -> AgentState:
        """Execute analyzer agent."""
        state.current_step = "analyzing"
        
        try:
            if state.task_type == "paper2code":
                await self._generate_code_plan(state)
            else:
                await self._analyze_paper(state)
        except Exception as e:
            logger.error(f"Analyzer error: {e}")
            state.errors.append(f"Analysis failed: {str(e)}")
        
        return state
    
    async def _analyze_paper(self, state: AgentState) -> None:
        """Perform comprehensive paper analysis."""
        paper = state.current_paper
        if not paper:
            state.errors.append("No paper to analyze")
            return
        
        # Check for existing analysis
        existing = self.db.get_latest_analysis(paper.id, "full")
        if existing:
            state.analysis = existing.content
            return
        
        # Download PDF if needed
        if not paper.pdf_path or not Path(paper.pdf_path).exists():
            pdf_dir = self.settings.data_dir / "pdfs" / paper.published_date.strftime("%Y/%m")
            paper.pdf_path = await self.api_client.download_pdf(paper, str(pdf_dir))
            self.db.save_paper(paper)
        
        # Process PDF
        processed = self.pdf_processor.process(paper.pdf_path)
        paper.pdf_hash = processed.pdf_hash
        
        # Index chunks
        chunks = self._create_chunks(paper.id, processed)
        self.vector_store.add_chunks(chunks)
        
        # Generate analysis with LLM
        prompt = ANALYSIS_PROMPT_TEMPLATE.format(
            title=paper.title,
            authors=", ".join(paper.authors[:5]),
            content=processed.markdown[:30000],  # Truncate for context window
        )
        
        response = await self.llm.generate(
            prompt=prompt,
            system=ANALYSIS_SYSTEM_PROMPT,
            temperature=0.3,
        )
        
        # Save analysis
        analysis = Analysis(
            paper_id=paper.id,
            analysis_type="full",
            content={"text": response.content, "sections": processed.sections},
            model_used=response.model,
            token_count=response.input_tokens + response.output_tokens,
        )
        self.db.save_analysis(analysis)
        
        state.analysis = analysis.content
        state.current_paper = paper
    
    async def _generate_code_plan(self, state: AgentState) -> None:
        """Generate paper-to-code implementation plan."""
        paper = state.current_paper
        if not paper:
            state.errors.append("No paper for code generation")
            return
        
        # Ensure PDF is processed
        if not paper.pdf_path:
            pdf_dir = self.settings.data_dir / "pdfs" / paper.published_date.strftime("%Y/%m")
            paper.pdf_path = await self.api_client.download_pdf(paper, str(pdf_dir))
        
        processed = self.pdf_processor.process(paper.pdf_path)
        
        # Generate implementation plan using Claude Opus
        plan_schema = {
            "type": "object",
            "properties": {
                "architecture": {"type": "string"},
                "components": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "file": {"type": "string"},
                            "description": {"type": "string"},
                            "dependencies": {"type": "array", "items": {"type": "string"}},
                        },
                    },
                },
                "python_dependencies": {"type": "array", "items": {"type": "string"}},
                "implementation_order": {"type": "array", "items": {"type": "string"}},
            },
            "required": ["architecture", "components", "python_dependencies", "implementation_order"],
        }
        
        plan_prompt = f"""Analyze this research paper and create a detailed implementation plan.

Title: {paper.title}

Paper Content:
{processed.markdown[:40000]}

Create a comprehensive implementation plan that would allow a developer to reproduce the paper's methodology in Python. Focus on the core algorithm and architecture."""
        
        plan = await self.llm.generate_structured(
            prompt=plan_prompt,
            output_schema=plan_schema,
            model=self.settings.llm.model_code,  # Use Claude Opus for code
        )
        
        state.code_plan = plan
        
        # Save as analysis
        analysis = Analysis(
            paper_id=paper.id,
            analysis_type="code_plan",
            content=plan,
            model_used=self.settings.llm.model_code,
        )
        self.db.save_analysis(analysis)
    
    def _create_chunks(self, paper_id: str, processed) -> list[Chunk]:
        """Create chunks from processed paper."""
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.settings.chunking.chunk_size,
            chunk_overlap=self.settings.chunking.chunk_overlap,
            separators=["\n## ", "\n### ", "\n\n", "\n", " "],
        )
        
        chunks = []
        chunk_index = 0
        
        for section in processed.sections:
            section_chunks = splitter.split_text(section.content)
            
            for chunk_text in section_chunks:
                if len(chunk_text) < self.settings.chunking.min_chunk_size:
                    continue
                
                chunks.append(Chunk(
                    id=f"{paper_id}_{chunk_index}",
                    content=chunk_text,
                    paper_id=paper_id,
                    section=section.name,
                    chunk_index=chunk_index,
                ))
                chunk_index += 1
        
        return chunks

3.4 RAG Chat Agent
# src/arxiv_agent/agents/rag_chat.py
from loguru import logger

from arxiv_agent.agents.state import AgentState
from arxiv_agent.core.vector_store import get_vector_store
from arxiv_agent.core.llm_service import get_llm_service
from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.storage import get_db


RAG_SYSTEM_PROMPT = """You are a research assistant helping users understand academic papers.
Use the retrieved context to answer questions accurately.
Always cite the relevant sections when providing information.
If the context doesn't contain enough information, say so clearly.
Be concise but thorough in your explanations."""


class RAGChatAgent:
    """Agent for interactive RAG-based paper Q&A."""
    
    def __init__(self):
        self.vector_store = get_vector_store()
        self.llm = get_llm_service()
        self.settings = get_settings()
        self.db = get_db()
    
    async def run(self, state: AgentState) -> AgentState:
        """Execute RAG chat agent."""
        state.current_step = "chatting"
        
        try:
            await self._process_query(state)
        except Exception as e:
            logger.error(f"RAG chat error: {e}")
            state.errors.append(f"Chat failed: {str(e)}")
        
        return state
    
    async def _process_query(self, state: AgentState) -> None:
        """Process a chat query with RAG."""
        if not state.query:
            state.errors.append("No query provided")
            return
        
        paper_id = state.paper_id
        
        # Get or create chat session
        session = self.db.get_or_create_chat_session(paper_id)
        
        # Retrieve relevant context
        results = self.vector_store.hybrid_search(
            query=state.query,
            paper_id=paper_id,
            k=self.settings.retrieval.top_k,
        )
        
        # Build context
        context_parts = []
        for i, result in enumerate(results[:self.settings.retrieval.rerank_top_k]):
            context_parts.append(
                f"[Section: {result.chunk.section}]\n{result.chunk.content}"
            )
        
        context = "\n\n---\n\n".join(context_parts)
        
        # Get chat history
        history = self.db.get_chat_history(session.id, limit=10)
        history_text = "\n".join([
            f"{msg.role.upper()}: {msg.content}" for msg in history[-6:]
        ])
        
        # Build prompt
        prompt = f"""Paper Context:
{context}

Previous Conversation:
{history_text}

User Question: {state.query}

Provide a helpful, accurate response based on the paper content."""
        
        # Generate response
        response = await self.llm.generate(
            prompt=prompt,
            system=RAG_SYSTEM_PROMPT,
            temperature=0.5,
        )
        
        # Save messages
        self.db.add_chat_message(session.id, "user", state.query)
        self.db.add_chat_message(
            session.id,
            "assistant",
            response.content,
            retrieved_chunks=[
                {"id": r.chunk.id, "section": r.chunk.section, "score": r.score}
                for r in results[:5]
            ],
        )
        
        # Update state
        state.chat_history.append({"role": "user", "content": state.query})
        state.chat_history.append({"role": "assistant", "content": response.content})
        state.retrieved_chunks = [
            {"content": r.chunk.content, "section": r.chunk.section}
            for r in results[:5]
        ]
        
        # Record interaction for learning
        self.db.record_interaction(paper_id, "chatted")

Phase 4: CLI Interface (Week 4-5)
4.1 Main CLI Application
# src/arxiv_agent/cli/main.py
import asyncio
from typing import Optional

import typer
from rich.console import Console

from arxiv_agent.cli.commands import search, analyze, chat, digest, library, trends, config
from arxiv_agent.config.settings import get_settings

app = typer.Typer(
    name="arxiv-agent",
    help="ğŸ”¬ Multi-agent CLI for research paper discovery and analysis",
    rich_markup_mode="rich",
    no_args_is_help=True,
)

console = Console()

# Register command groups
app.add_typer(search.app, name="search", help="ğŸ” Search for research papers")
app.add_typer(analyze.app, name="analyze", help="ğŸ“Š Deep paper analysis")
app.add_typer(chat.app, name="chat", help="ğŸ’¬ Interactive RAG chat")
app.add_typer(digest.app, name="digest", help="ğŸ“° Daily digest management")
app.add_typer(library.app, name="library", help="ğŸ“š Personal library management")
app.add_typer(trends.app, name="trends", help="ğŸ“ˆ Trending topics discovery")
app.add_typer(config.app, name="config", help="âš™ï¸ Settings management")


@app.callback()
def callback(
    verbose: bool = typer.Option(False, "--verbose", "-v", help="Enable verbose output"),
    quiet: bool = typer.Option(False, "--quiet", "-q", help="Minimal output"),
    no_color: bool = typer.Option(False, "--no-color", help="Disable colored output"),
):
    """ArxivAgent - Your AI-powered research assistant."""
    import sys
    from loguru import logger
    
    # Configure logging
    logger.remove()
    if verbose:
        logger.add(sys.stderr, level="DEBUG")
    elif not quiet:
        logger.add(sys.stderr, level="INFO", format="{message}")
    
    # Initialize settings
    settings = get_settings()
    settings.ensure_directories()
    
    # Disable colors if requested
    if no_color:
        console.no_color = True


@app.command()
def version():
    """Show version information."""
    from arxiv_agent import __version__
    console.print(f"[bold blue]arxiv-agent[/] version {__version__}")


@app.command()
def quickstart():
    """Interactive setup wizard."""
    from arxiv_agent.cli.commands.config import setup_wizard
    asyncio.run(setup_wizard())


def main():
    """Entry point."""
    app()


if __name__ == "__main__":
    main()

4.2 Search Commands
# src/arxiv_agent/cli/commands/search.py
import asyncio
from typing import Optional

import typer
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.panel import Panel
from rich.markdown import Markdown

from arxiv_agent.agents.orchestrator import get_orchestrator
from arxiv_agent.config.settings import get_settings

app = typer.Typer()
console = Console()


@app.callback(invoke_without_command=True)
def search(
    query: str = typer.Argument(..., help="Search query"),
    limit: int = typer.Option(10, "--limit", "-n", help="Number of results"),
    category: Optional[str] = typer.Option(None, "--category", "-c", help="arXiv category"),
    since: Optional[str] = typer.Option(None, "--since", help="Papers since date (YYYY-MM-DD)"),
    sort: str = typer.Option("relevance", "--sort", "-s", help="Sort by: relevance, date, citations"),
    save: bool = typer.Option(False, "--save", help="Save results to library"),
):
    """ğŸ” Search for research papers on arXiv."""
    asyncio.run(_search(query, limit, category, since, sort, save))


async def _search(
    query: str,
    limit: int,
    category: Optional[str],
    since: Optional[str],
    sort: str,
    save: bool,
):
    """Execute search."""
    orchestrator = get_orchestrator()
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Searching arXiv...", total=None)
        
        result = await orchestrator.run(
            task_type="search",
            query=query,
        )
    
    if result.errors:
        console.print(f"[red]Error:[/] {result.errors[0]}")
        raise typer.Exit(1)
    
    if not result.papers:
        console.print("[yellow]No papers found matching your query.[/]")
        return
    
    # Display results
    table = Table(
        title=f"ğŸ“„ Search Results for '{query}'",
        show_header=True,
        header_style="bold magenta",
    )
    table.add_column("#", style="dim", width=4)
    table.add_column("Title", style="cyan", no_wrap=False, max_width=60)
    table.add_column("Authors", style="green", max_width=30)
    table.add_column("Date", style="blue", width=12)
    table.add_column("Citations", justify="right", style="yellow", width=10)
    
    for i, paper in enumerate(result.papers[:limit], 1):
        authors = ", ".join(paper.authors[:3])
        if len(paper.authors) > 3:
            authors += f" +{len(paper.authors) - 3}"
        
        date_str = paper.published_date.strftime("%Y-%m-%d") if paper.published_date else "N/A"
        
        table.add_row(
            str(i),
            paper.title[:80] + ("..." if len(paper.title) > 80 else ""),
            authors,
            date_str,
            str(paper.citation_count),
        )
    
    console.print(table)
    console.print()
    
    # Show interaction prompt
    console.print("[dim]Use 'arxiv-agent analyze <paper_id>' to analyze a paper[/]")
    console.print("[dim]Use 'arxiv-agent chat <paper_id>' to start a chat session[/]")


@app.command("paper")
def search_paper(
    paper_id: str = typer.Argument(..., help="Paper ID (e.g., arxiv:2401.12345)"),
):
    """ğŸ“„ Get details for a specific paper."""
    asyncio.run(_get_paper(paper_id))


async def _get_paper(paper_id: str):
    """Get paper details."""
    orchestrator = get_orchestrator()
    
    # Normalize ID
    if not paper_id.startswith("arxiv:"):
        paper_id = f"arxiv:{paper_id}"
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        progress.add_task("Fetching paper...", total=None)
        
        result = await orchestrator.run(
            task_type="search",
            paper_id=paper_id,
        )
    
    if result.errors or not result.current_paper:
        console.print(f"[red]Paper not found: {paper_id}[/]")
        raise typer.Exit(1)
    
    paper = result.current_paper
    
    # Display paper details
    panel_content = f"""**Title:** {paper.title}

**Authors:** {', '.join(paper.authors)}

**Categories:** {', '.join(paper.categories)}

**Published:** {paper.published_date.strftime('%Y-%m-%d') if paper.published_date else 'N/A'}

**Citations:** {paper.citation_count}

**Abstract:**
{paper.abstract}

{f'**TLDR:** {paper.tldr}' if paper.tldr else ''}
"""
    
    console.print(Panel(
        Markdown(panel_content),
        title=f"[bold blue]{paper.id}[/]",
        border_style="blue",
    ))

4.3 Chat Commands
# src/arxiv_agent/cli/commands/chat.py
import asyncio
from typing import Optional

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.live import Live
from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory

from arxiv_agent.agents.orchestrator import get_orchestrator
from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.storage import get_db

app = typer.Typer()
console = Console()


@app.callback(invoke_without_command=True)
def chat(
    paper_id: str = typer.Argument(..., help="Paper ID to chat about"),
):
    """ğŸ’¬ Start an interactive RAG chat session with a paper."""
    asyncio.run(_chat_session(paper_id))


async def _chat_session(paper_id: str):
    """Run interactive chat session."""
    # Normalize ID
    if not paper_id.startswith("arxiv:"):
        paper_id = f"arxiv:{paper_id}"
    
    orchestrator = get_orchestrator()
    settings = get_settings()
    db = get_db()
    
    # Get paper info
    paper = db.get_paper(paper_id)
    if not paper:
        console.print(f"[red]Paper not found: {paper_id}[/]")
        console.print("[dim]Use 'arxiv-agent search' to find papers first[/]")
        raise typer.Exit(1)
    
    console.print(Panel(
        f"[bold]{paper.title}[/]\n\n[dim]Type your questions below. Use /help for commands, /quit to exit.[/]",
        title="ğŸ’¬ Chat Session",
        border_style="green",
    ))
    
    # Setup prompt with history
    history_file = settings.data_dir / "chat_history.txt"
    session = PromptSession(history=FileHistory(str(history_file)))
    
    while True:
        try:
            # Get user input
            user_input = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: session.prompt("\n[You] > "),
            )
            
            if not user_input.strip():
                continue
            
            # Handle commands
            if user_input.startswith("/"):
                if user_input.lower() in ["/quit", "/exit", "/q"]:
                    console.print("[dim]Goodbye![/]")
                    break
                elif user_input.lower() == "/help":
                    console.print("""
[bold]Commands:[/]
  /quit, /exit, /q - Exit chat
  /help - Show this help
  /history - Show chat history
  /clear - Clear chat history
  /sources - Show retrieved sources for last answer
""")
                    continue
                elif user_input.lower() == "/history":
                    _show_history(paper_id)
                    continue
            
            # Process query
            console.print()
            result = await orchestrator.run(
                task_type="chat",
                paper_id=paper_id,
                query=user_input,
            )
            
            if result.errors:
                console.print(f"[red]Error: {result.errors[0]}[/]")
                continue
            
            # Display response
            if result.chat_history:
                response = result.chat_history[-1]["content"]
                console.print(Panel(
                    Markdown(response),
                    title="[bold blue]Claude[/]",
                    border_style="blue",
                ))
            
        except KeyboardInterrupt:
            console.print("\n[dim]Use /quit to exit[/]")
        except EOFError:
            break


def _show_history(paper_id: str):
    """Show chat history for paper."""
    db = get_db()
    session = db.get_or_create_chat_session(paper_id)
    messages = db.get_chat_history(session.id, limit=20)
    
    if not messages:
        console.print("[dim]No chat history[/]")
        return
    
    for msg in messages:
        role = "[bold green]You[/]" if msg.role == "user" else "[bold blue]Claude[/]"
        console.print(f"\n{role}: {msg.content[:200]}{'...' if len(msg.content) > 200 else ''}")


@app.command("history")
def show_history(
    paper_id: Optional[str] = typer.Argument(None, help="Paper ID"),
    session_id: Optional[str] = typer.Option(None, "--session", "-s", help="Session ID"),
):
    """ğŸ“œ Show chat history."""
    if paper_id:
        if not paper_id.startswith("arxiv:"):
            paper_id = f"arxiv:{paper_id}"
        _show_history(paper_id)
    else:
        # List all sessions
        console.print("[dim]Specify a paper ID to view history[/]")


@app.command("export")
def export_chat(
    session_id: str = typer.Argument(..., help="Session ID to export"),
    output: str = typer.Option("chat_export.md", "--output", "-o", help="Output file"),
):
    """ğŸ“¤ Export chat session to markdown."""
    db = get_db()
    messages = db.get_chat_history(session_id, limit=1000)
    
    if not messages:
        console.print("[red]Session not found[/]")
        raise typer.Exit(1)
    
    with open(output, "w") as f:
        f.write(f"# Chat Export - Session {session_id}\n\n")
        for msg in messages:
            role = "**You**" if msg.role == "user" else "**Claude**"
            f.write(f"{role}:\n\n{msg.content}\n\n---\n\n")
    
    console.print(f"[green]Exported to {output}[/]")

Phase 5: Advanced Features (Week 5-6)
5.1 Paper-to-Code Generator
# src/arxiv_agent/cli/commands/paper2code.py
import asyncio
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from rich.syntax import Syntax
from rich.panel import Panel
from rich.tree import Tree

from arxiv_agent.agents.orchestrator import get_orchestrator
from arxiv_agent.core.llm_service import get_llm_service
from arxiv_agent.config.settings import get_settings

app = typer.Typer()
console = Console()


CODE_GENERATION_PROMPT = """Based on the implementation plan and paper content, generate production-quality Python code for the component: {component_name}

Implementation Plan:
{plan}

Paper Context:
{context}

Requirements:
- Use type hints throughout
- Include comprehensive docstrings with paper section references
- Follow PEP 8 style guidelines
- Include error handling
- Make the code modular and testable

Generate the complete implementation for {file_name}:"""


@app.callback(invoke_without_command=True)
def paper2code(
    paper_id: str = typer.Argument(..., help="Paper ID to implement"),
    output: Path = typer.Option(
        Path("./implementation"),
        "--output", "-o",
        help="Output directory",
    ),
    framework: str = typer.Option(
        "pytorch",
        "--framework", "-f",
        help="Target framework: pytorch, jax, tensorflow",
    ),
    tests: bool = typer.Option(True, "--tests/--no-tests", help="Generate tests"),
    dry_run: bool = typer.Option(False, "--dry-run", help="Preview without generating"),
):
    """ğŸ”§ Generate code implementation from a research paper."""
    asyncio.run(_generate_code(paper_id, output, framework, tests, dry_run))


async def _generate_code(
    paper_id: str,
    output: Path,
    framework: str,
    tests: bool,
    dry_run: bool,
):
    """Generate code from paper."""
    if not paper_id.startswith("arxiv:"):
        paper_id = f"arxiv:{paper_id}"
    
    orchestrator = get_orchestrator()
    llm = get_llm_service()
    settings = get_settings()
    
    console.print(Panel(
        f"[bold]Generating implementation for {paper_id}[/]\n"
        f"Framework: {framework}\n"
        f"Output: {output}",
        title="ğŸ”§ Paper2Code",
        border_style="blue",
    ))
    
    # Step 1: Generate implementation plan
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Analyzing paper and creating plan...", total=None)
        
        result = await orchestrator.run(
            task_type="paper2code",
            paper_id=paper_id,
        )
    
    if result.errors:
        console.print(f"[red]Error: {result.errors[0]}[/]")
        raise typer.Exit(1)
    
    plan = result.code_plan
    if not plan:
        console.print("[red]Failed to generate implementation plan[/]")
        raise typer.Exit(1)
    
    # Display plan
    console.print("\n[bold green]Implementation Plan:[/]\n")
    console.print(f"[bold]Architecture:[/] {plan.get('architecture', 'N/A')}")
    
    tree = Tree("ğŸ“ Project Structure")
    for component in plan.get("components", []):
        tree.add(f"ğŸ“„ {component['file']} - {component['name']}")
    console.print(tree)
    
    console.print(f"\n[bold]Dependencies:[/] {', '.join(plan.get('python_dependencies', []))}")
    
    if dry_run:
        console.print("\n[yellow]Dry run - no files generated[/]")
        return
    
    # Confirm generation
    if not typer.confirm("\nProceed with code generation?"):
        raise typer.Abort()
    
    # Step 2: Generate code for each component
    output.mkdir(parents=True, exist_ok=True)
    
    components = plan.get("components", [])
    impl_order = plan.get("implementation_order", [c["file"] for c in components])
    
    generated_files = {}
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("{task.completed}/{task.total}"),
        console=console,
    ) as progress:
        task = progress.add_task("Generating code...", total=len(impl_order))
        
        for file_name in impl_order:
            component = next(
                (c for c in components if c["file"] == file_name),
                None
            )
            if not component:
                continue
            
            progress.update(task, description=f"Generating {file_name}...")
            
            # Generate code
            prompt = CODE_GENERATION_PROMPT.format(
                component_name=component["name"],
                plan=str(plan),
                context=component.get("description", ""),
                file_name=file_name,
            )
            
            response = await llm.generate(
                prompt=prompt,
                model=settings.llm.model_code,
                temperature=0.2,
                max_tokens=8000,
            )
            
            # Extract code from response
            code = _extract_code(response.content)
            
            # Save file
            file_path = output / "src" / file_name
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(code)
            
            generated_files[file_name] = code
            progress.advance(task)
    
    # Step 3: Generate project files
    await _generate_project_files(output, plan, paper_id)
    
    if tests:
        await _generate_tests(output, generated_files, plan, llm, settings)
    
    console.print(f"\n[bold green]âœ… Generated implementation at {output}[/]")
    console.print("\n[dim]Next steps:[/]")
    console.print(f"  cd {output}")
    console.print("  uv venv && source .venv/bin/activate")
    console.print("  uv pip install -e .")
    console.print("  pytest tests/")


def _extract_code(response: str) -> str:
    """Extract code from LLM response."""
    import re
    
    # Try to find code blocks
    code_blocks = re.findall(r"```python\n(.*?)```", response, re.DOTALL)
    if code_blocks:
        return code_blocks[0].strip()
    
    # Fall back to entire response
    return response.strip()


async def _generate_project_files(output: Path, plan: dict, paper_id: str):
    """Generate pyproject.toml and README."""
    # pyproject.toml
    deps = plan.get("python_dependencies", ["torch", "numpy"])
    deps_str = ",\n    ".join(f'"{d}"' for d in deps)
    
    pyproject = f'''[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "paper-implementation"
version = "0.1.0"
description = "Implementation of {paper_id}"
requires-python = ">=3.10"
dependencies = [
    {deps_str}
]

[project.optional-dependencies]
dev = ["pytest", "pytest-cov", "ruff", "mypy"]
'''
    
    (output / "pyproject.toml").write_text(pyproject)
    
    # README
    readme = f'''# Paper Implementation

Implementation of [{paper_id}](https://arxiv.org/abs/{paper_id.replace("arxiv:", "")})

## Installation

```bash
uv venv
source .venv/bin/activate
uv pip install -e ".[dev]"

Usage
from src.model import Model

model = Model()
output = model(input_data)

Architecture
{plan.get("architecture", "See paper for details.")}

Generated by
arxiv-agent - AI-powered paper to code
'''

(output / "README.md").write_text(readme)

async def _generate_tests(output: Path, files: dict, plan: dict, llm, settings):
"""Generate pytest tests."""
tests_dir = output / "tests"
tests_dir.mkdir(exist_ok=True)

# Generate tests for each file
for file_name, code in files.items():
    test_prompt = f"""Generate comprehensive pytest tests for this code:

{code}

Include:

Unit tests for each function/class
Edge cases
Type checking
Example usage tests
Generate the complete test file:"""

    response = await llm.generate(
        prompt=test_prompt,
        model=settings.llm.model,
        temperature=0.2,
    )
    
    test_code = _extract_code(response.content)
    test_file = tests_dir / f"test_{Path(file_name).stem}.py"
    test_file.write_text(test_code)


### 5.2 Daily Digest Commands

```python
# src/arxiv_agent/cli/commands/digest.py
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

from arxiv_agent.agents.orchestrator import get_orchestrator
from arxiv_agent.config.settings import get_settings
from arxiv_agent.data.storage import get_db

app = typer.Typer()
console = Console()


@app.command("config")
def configure_digest(
    keywords: Optional[str] = typer.Option(None, "--keywords", "-k", help="Comma-separated keywords"),
    time: Optional[str] = typer.Option(None, "--time", "-t", help="Delivery time (HH:MM)"),
    papers: Optional[int] = typer.Option(None, "--papers", "-n", help="Papers per digest (max 10)"),
    categories: Optional[str] = typer.Option(None, "--categories", "-c", help="arXiv categories"),
):
    """âš™ï¸ Configure daily digest settings."""
    settings = get_settings()
    
    if keywords:
        settings.digest.keywords = [k.strip() for k in keywords.split(",")]
    if time:
        settings.digest.schedule_time = time
    if papers:
        settings.digest.max_papers = min(papers, 10)
    if categories:
        settings.digest.categories = [c.strip() for c in categories.split(",")]
    
    # Display current config
    console.print(Panel(
        f"""[bold]Current Digest Configuration:[/]

Keywords: {', '.join(settings.digest.keywords) or '[dim]None[/]'}
Time: {settings.digest.schedule_time}
Max Papers: {settings.digest.max_papers}
Categories: {', '.join(settings.digest.categories)}
Enabled: {'âœ…' if settings.digest.enabled else 'âŒ'}
""",
        title="ğŸ“° Digest Settings",
        border_style="blue",
    ))


@app.command("run")
def run_digest(
    dry_run: bool = typer.Option(False, "--dry-run", help="Preview without saving"),
):
    """ğŸš€ Run daily digest now."""
    asyncio.run(_run_digest(dry_run))


async def _run_digest(dry_run: bool):
    """Execute digest generation."""
    orchestrator = get_orchestrator()
    settings = get_settings()
    
    console.print("[bold blue]Generating daily digest...[/]\n")
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Fetching and analyzing papers...", total=None)
        
        result = await orchestrator.run(task_type="digest")
    
    if result.errors:
        console.print(f"[red]Error: {result.errors[0]}[/]")
        raise typer.Exit(1)
    
    if not result.papers:
        console.print("[yellow]No new papers found matching your keywords.[/]")
        return
    
    # Generate markdown report
    date_str = datetime.now().strftime("%Y-%m-%d")
    report = _generate_digest_report(result.papers, date_str)
    
    # Display report
    console.print(Panel(
        Markdown(report),
        title=f"ğŸ“° Daily Digest - {date_str}",
        border_style="green",
    ))
    
    if not dry_run:
        # Save report
        digest_path = settings.data_dir / "digests" / f"{date_str}.md"
        digest_path.parent.mkdir(parents=True, exist_ok=True)
        digest_path.write_text(report)
        console.print(f"\n[dim]Saved to {digest_path}[/]")


def _generate_digest_report(papers: list, date_str: str) -> str:
    """Generate markdown digest report."""
    lines = [
        f"# Daily Research Digest - {date_str}",
        "",
        f"Found **{len(papers)}** papers matching your interests.",
        "",
        "## ğŸ”¥ Top Papers",
        "",
    ]
    
    for i, paper in enumerate(papers, 1):
        lines.extend([
            f"### {i}. {paper.title}",
            "",
            f"**Authors:** {', '.join(paper.authors[:5])}{'...' if len(paper.authors) > 5 else ''}",
            "",
            f"**Categories:** {', '.join(paper.categories)}",
            "",
            f"**Citations:** {paper.citation_count}",
            "",
            f"**ID:** `{paper.id}`",
            "",
            f"**Abstract:**",
            f"> {paper.abstract[:500]}{'...' if len(paper.abstract) > 500 else ''}",
            "",
            f"{f'**TLDR:** {paper.tldr}' if paper.tldr else ''}",
            "",
            "---",
            "",
        ])
    
    lines.extend([
        "",
        "## Quick Actions",
        "",
        "```bash",
        "# Analyze a paper",
        f"arxiv-agent analyze {papers[0].id if papers else 'arxiv:XXXX.XXXXX'}",
        "",
        "# Start a chat session",
        f"arxiv-agent chat {papers[0].id if papers else 'arxiv:XXXX.XXXXX'}",
        "",
        "# Add to library",
        f"arxiv-agent library add {papers[0].id if papers else 'arxiv:XXXX.XXXXX'}",
        "```",
    ])
    
    return "\n".join(lines)


@app.command("schedule")
def manage_schedule(
    action: str = typer.Argument(..., help="enable, disable, or status"),
):
    """â° Manage digest scheduling."""
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
    
    settings = get_settings()
    
    if action == "status":
        console.print(f"Digest scheduling: {'[green]enabled[/]' if settings.digest.enabled else '[red]disabled[/]'}")
        console.print(f"Scheduled time: {settings.digest.schedule_time}")
        return
    
    if action == "enable":
        settings.digest.enabled = True
        console.print("[green]âœ… Digest scheduling enabled[/]")
        console.print(f"[dim]Digests will be generated daily at {settings.digest.schedule_time}[/]")
    elif action == "disable":
        settings.digest.enabled = False
        console.print("[yellow]â¸ï¸ Digest scheduling disabled[/]")
    else:
        console.print("[red]Invalid action. Use: enable, disable, or status[/]")


@app.command("show")
def show_digest(
    date: Optional[str] = typer.Argument(None, help="Date (YYYY-MM-DD)"),
):
    """ğŸ“– Show digest for a specific date."""
    settings = get_settings()
    
    if not date:
        date = datetime.now().strftime("%Y-%m-%d")
    
    digest_path = settings.data_dir / "digests" / f"{date}.md"
    
    if not digest_path.exists():
        console.print(f"[yellow]No digest found for {date}[/]")
        console.print("[dim]Use 'arxiv-agent digest run' to generate one[/]")
        return
    
    content = digest_path.read_text()
    console.print(Markdown(content))


@app.command("list")
def list_digests():
    """ğŸ“‹ List all available digests."""
    settings = get_settings()
    digest_dir = settings.data_dir / "digests"
    
    if not digest_dir.exists():
        console.print("[dim]No digests found[/]")
        return
    
    digests = sorted(digest_dir.glob("*.md"), reverse=True)
    
    if not digests:
        console.print("[dim]No digests found[/]")
        return
    
    console.print("[bold]Available Digests:[/]\n")
    for digest_file in digests[:20]:
        date = digest_file.stem
        console.print(f"  ğŸ“° {date}")
    
    if len(digests) > 20:
        console.print(f"\n[dim]...and {len(digests) - 20} more[/]")

Installation & Usage
Single-Command Installation
# Option 1: Using uv (recommended - fastest)
curl -LsSf https://astral.sh/uv/install.sh | sh
uv tool install arxiv-agent

# Option 2: Using pipx
pipx install arxiv-agent

# Option 3: From source
git clone https://github.com/yourusername/arxiv-agent
cd arxiv-agent
uv pip install -e ".[dev]"

Quick Start
# 1. Configure API key
arxiv-agent config api-keys set anthropic YOUR_API_KEY

# 2. Set your research interests
arxiv-agent digest config --keywords "transformer,attention,llm,agents"

# 3. Search for papers
arxiv-agent search "multi-agent systems"

# 4. Analyze a paper
arxiv-agent analyze arxiv:2401.12345

# 5. Chat with a paper
arxiv-agent chat arxiv:2401.12345

# 6. Generate code from paper
arxiv-agent paper2code arxiv:2401.12345 --output ./my-implementation

# 7. Enable daily digests
arxiv-agent digest schedule enable

Development Timeline
Week	Phase	Deliverables
1-2	Foundation	Project setup, config, DB models, storage
2-3	Core Services	API clients, PDF processing, vector store, LLM service
3-4	Agents	Fetcher, Analyzer, RAG Chat, Librarian, Orchestrator
4-5	CLI Interface	All command groups, theming, progress indicators
5-6	Advanced Features	Paper2Code, daily digests, trends, learning system
6+	Polish	Testing, documentation, CI/CD, optimization
This implementation provides a solid, production-grade foundation that you can extend and customize based on your specific needs. The modular architecture allows for easy testing and maintenance, while the agent-based design enables complex workflows with clear separation of concerns.

based on provided information plan a complete production ready repo from scratch along with end-to-end test it to make sure everything is running and working start working on it.